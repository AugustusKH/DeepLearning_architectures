{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5At28uyZsEh"
      },
      "source": [
        "Department of Mathematics and Computer Science, Faculty of Science, Chulalongkorn University\n",
        "\n",
        "2301648 Architectures of Deep Learning  \n",
        "\n",
        "First Semester, Saturday 2 March 2024, 8:30 - 12:00"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRaeg7RPZsEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8732b81-f46a-4a4c-aeec-f7fd41e136e7"
      },
      "source": [
        "# Must run this statement first\n",
        "!pip install --quiet numpy==1.23.1 mxnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.85 requires numpy>=1.24.1, but you have numpy 1.23.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"30\" color=\"red\">You must restart session to continue.</font>"
      ],
      "metadata": {
        "id": "plPI0019kT45"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mAEonxvZsEs"
      },
      "source": [
        "**Instructions**\n",
        "\n",
        "1. There are 6 questions in this exam.  \n",
        "2. Type in your Student ID and full name in the box below.  \n",
        "3. You must not distribute any part of this exam through any other persons. The exam is a government's property. Violators will be prosecuted under a criminal court.  \n",
        "4. Once the time is expired, student must stop typing.  \n",
        "5. Any student who does not obey the regulations listed above will receive punishment under the Faculty of Engineering Official Announcement on January 6, 2003 regarding the exam regulations.  \n",
        "\n",
        "** With implicit evidence or showing intention for cheating, student will receive an F in this course and will receive an academic suspension for 1 semester.**  \n",
        "\n",
        "**With explicit evidence for cheating, student will receive an F in this course and will receive an academic suspension for 1 year.**  \n",
        "\n",
        "I acknowledge all instructions above. This exam represents only my own work. I did not give or receive help on this exam.  \n",
        "\n",
        "Type in your name and date below.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uzWzmZDZsEt"
      },
      "source": [
        "## &#48;. Type in your student ID and Name here\n",
        "ID ....................\n",
        "Name .............................................."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCEU172qZsEu"
      },
      "source": [
        "%matplotlib inline\n",
        "# DO NOT CHANGE THIS BOX\n",
        "# Run it to import all necessary libraries\n",
        "import mxnet as mx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mxnet import nd, autograd\n",
        "from mxnet.gluon import nn, loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlJBtTs6ZsEw"
      },
      "source": [
        "## &#49;. Deep Learning concept (10 points)\n",
        "\n",
        "What are different among (1) the perceptron, (2) the multilayer perceptron, and (3) the convolutional neural network? For each model, you must give the mathematical descriptions or MXNet statement to represent them. Then explain it with some examples.  \n",
        "\n",
        "2 points will be given to the correct mathematical descriptions of each model. (Total of 6 points). 2 points will be given if the different between these three models are described. 2 points will be assign to examples for each model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution 1. (Your complete solution must type in this box.)\n"
      ],
      "metadata": {
        "id": "TxBvlzWAsA6X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS1mw68ZsEy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4eky8N-ZsE1"
      },
      "source": [
        "## &#50;. NDArray (10 points)\n",
        "Given NDArrays: $x_1$, $x_2$, $x_3$, $x_4$, $x_5$, $x_6$, $x_7$ and three constants $m$, $n$, and $k$. Find the expression that would generate the following results. You are not allowed to type any digit in your expression unless it is used for indexing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGj9LcSnZsE2"
      },
      "source": [
        "# Must run this box to get all NDArrays and constants.\n",
        "m, n, k = 4, 5, 7\n",
        "x_1, x_2, x_3 = nd.array([-2.0]), nd.arange(m), nd.array([[4, -1, 1], [0, 2, 3]])\n",
        "x_4, x_5, x_6 = nd.ones((k-m,n)), nd.array([4, 0, 1, 2, 3]), nd.ones_like(x_3)\n",
        "x_7 = nd.array([[[2, 1], [-1, 2]], [[1, 0], [1, -1]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmoRIdo474YD",
        "outputId": "aaf4ec42-2074-48f5-f58a-dd9a4b59aad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[-2.]\n",
              "<NDArray 1 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ_3qHx877Qb",
        "outputId": "1357c276-6da7-4518-ff59-c9823e260cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[0. 1. 2. 3.]\n",
              "<NDArray 4 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlOG_WZU79MO",
        "outputId": "18681bec-826a-4b91-b7c2-0571fc98de1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 4. -1.  1.]\n",
              " [ 0.  2.  3.]]\n",
              "<NDArray 2x3 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1QdwePF7-su",
        "outputId": "0e21296c-6a28-4a8f-d5e6-f85590de85bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1. 1. 1. 1. 1.]\n",
              " [1. 1. 1. 1. 1.]\n",
              " [1. 1. 1. 1. 1.]]\n",
              "<NDArray 3x5 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YF17NSF8As_",
        "outputId": "ff27de8f-ef96-4020-ba42-c582e3540c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[4. 0. 1. 2. 3.]\n",
              "<NDArray 5 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0JPCok28CkE",
        "outputId": "2f4e10f0-d8af-466e-d361-8671d988b15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1. 1. 1.]\n",
              " [1. 1. 1.]]\n",
              "<NDArray 2x3 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1EjRoXV8EMk",
        "outputId": "284c4047-3e2e-44a9-ef1b-c9719f1efdc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[ 2.  1.]\n",
              "  [-1.  2.]]\n",
              "\n",
              " [[ 1.  0.]\n",
              "  [ 1. -1.]]]\n",
              "<NDArray 2x2x2 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVNaZznuZsE4",
        "outputId": "01b2922e-8bf3-4df2-9501-c38156fd25b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.1. The expression to generate\n",
        "# [[ 8. -2.  2.]\n",
        "#  [ 0.  4.  6.]]\n",
        "#<NDArray 2x3 @cpu(0)>\n",
        "# is\n",
        "x_3 * x_3[1,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 8. -2.  2.]\n",
              " [ 0.  4.  6.]]\n",
              "<NDArray 2x3 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPM8607tZsE7",
        "outputId": "eece4a17-aa97-48eb-e382-1876c9325362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.2. The expression to generate\n",
        "# [[6.  1.  3.]\n",
        "#  [2.  4.  5.]]\n",
        "#<NDArray 2x3 @cpu(0)>\n",
        "# is\n",
        "x_3 + x_3[1,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[6. 1. 3.]\n",
              " [2. 4. 5.]]\n",
              "<NDArray 2x3 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4KreoXAZsE-",
        "outputId": "bc741607-f6ad-439c-b878-656ce5c8ecc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.3. The expression to multiply two ndarrays (Using .as_np_ndarray() to transform it to use with mx.np.matmul)\n",
        "# [[4., 4., 4., 4., 4.],\n",
        "#  [5., 5., 5., 5., 5.]]\n",
        "# <NDArray 2x5 @cpu(0)>\n",
        "# is\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[4. 4. 4. 4. 4.]\n",
              " [5. 5. 5. 5. 5.]]\n",
              "<NDArray 2x5 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2_np[1:3].reshape((-1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqduepyB96Yw",
        "outputId": "05f93d6e-ad26-47af-efbf-8ade9979b365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_6_np = x_6.as_np_ndarray()\n",
        "x_4_np = x_4.as_np_ndarray()\n",
        "x_2_np = x_2.as_np_ndarray()\n",
        "result = np.matmul(x_6_np, x_4_np) + x_2_np[1:3].reshape((-1,1))\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeYpCA_y80TG",
        "outputId": "c6d17ade-cc43-4afe-e295-73a13ae2d822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4., 4., 4., 4., 4.],\n",
              "       [5., 5., 5., 5., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVBMWPL5ZsFC",
        "outputId": "3eb0859d-ec9d-4be3-d023-e40898bb059c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.4. The expression to generate\n",
        "# [[[[ 0.]\n",
        "#    [ 0.]\n",
        "#    [ 0.]\n",
        "#    [ 0.]\n",
        "#    [ 0.]]]\n",
        "#  [[[ 4.]\n",
        "#    [ 0.]\n",
        "#    [ 1.]\n",
        "#    [ 2.]\n",
        "#    [ 3.]]]\n",
        "#  [[[ 8.]\n",
        "#    [ 0.]\n",
        "#    [ 2.]\n",
        "#    [ 4.]\n",
        "#    [ 6.]]]\n",
        "#  [[[12.]\n",
        "#    [ 0.]\n",
        "#    [ 3.]\n",
        "#    [ 6.]\n",
        "#    [ 9.]]]]\n",
        "# <NDArray 4x1x5x1 @cpu(0)>\n",
        "# is\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[[ 0.]\n",
              "   [ 0.]\n",
              "   [ 0.]\n",
              "   [ 0.]\n",
              "   [ 0.]]]\n",
              "\n",
              "\n",
              " [[[ 4.]\n",
              "   [ 0.]\n",
              "   [ 1.]\n",
              "   [ 2.]\n",
              "   [ 3.]]]\n",
              "\n",
              "\n",
              " [[[ 8.]\n",
              "   [ 0.]\n",
              "   [ 2.]\n",
              "   [ 4.]\n",
              "   [ 6.]]]\n",
              "\n",
              "\n",
              " [[[12.]\n",
              "   [ 0.]\n",
              "   [ 3.]\n",
              "   [ 6.]\n",
              "   [ 9.]]]]\n",
              "<NDArray 4x1x5x1 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKw75Gs0ZsFE",
        "outputId": "43c971a8-30ce-4988-cedd-6b82c7b582d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.5. The expression to generate\n",
        "# [[[-16.   0. -10.]\n",
        "#   [  8. -10. -10.]]\n",
        "#\n",
        "#  [[ -8.   2.  -2.]\n",
        "#   [ -8.   6.   4.]]]\n",
        "# <NDArray 2x2x3 @cpu(0)>\n",
        "# is\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[-16.   0. -10.]\n",
              "  [  8. -10. -10.]]\n",
              "\n",
              " [[ -8.   2.  -2.]\n",
              "  [ -8.   6.   4.]]]\n",
              "<NDArray 2x2x3 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IID3uD4ZZsFH"
      },
      "source": [
        "## &#51;. Naïve Bayes (10 points)\n",
        "\n",
        "The USPS digits dataset or simply USPS dataset is a collection of handwritten digits collected from US postal service. It is commonly used as a benchmark dataset in machine learning and pattern recognition research, particularly for tasks related to digit recognition or classification.\n",
        "\n",
        "The dataset consists of grayscale images of handwritten digits from 0 to 9. The images are of size 16x16 pixels."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "# Download and load the USPS dataset\n",
        "usps = fetch_openml('usps', version=2, data_home='.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N5seMltzCzg",
        "outputId": "86d9feda-9282-4539-eed5-e21de8e88afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform features and target\n",
        "# Need to transform X and y appropriately\n",
        "X, y = usps.data, usps.target\n",
        "\n",
        "# Split data into training and testing sets (optional)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
        "\n",
        "# Transform to NDArray\n",
        "X_train_mx, X_test_mx = nd.array(X_train), nd.array(X_test)\n",
        "y_train_mx, y_test_mx = nd.array(y_train), nd.array(y_test)"
      ],
      "metadata": {
        "id": "BMamLRz5zC2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mx[0]*-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeARMqFeG68G",
        "outputId": "fc64f39f-30f0-4bec-bb0d-309d0a8c67c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[ 1.        1.        0.999991  0.999102  0.973345  0.719918  0.111103\n",
              "  0.005652  0.656341  0.970748  0.994381  0.942661  0.854142  0.911566\n",
              "  0.981999  0.998964  1.        1.        0.999933  0.995066  0.908984\n",
              "  0.433516 -0.386894 -0.339835  0.557768  0.959094  0.964375  0.736102\n",
              "  0.405695  0.643099  0.92624   0.995727  1.        0.999993  0.99938\n",
              "  0.979795  0.760357  0.071274 -0.538563 -0.176287  0.658883  0.96517\n",
              "  0.864492  0.364123 -0.119492  0.340956  0.858014  0.99162   0.999998\n",
              "  0.999799  0.992972  0.903512  0.461992 -0.308998 -0.439492  0.255182\n",
              "  0.834841  0.946263  0.642277 -0.109225 -0.43479   0.224189  0.832744\n",
              "  0.990088  0.999958  0.997208  0.948173  0.649846 -0.039673 -0.492903\n",
              " -0.070086  0.650673  0.941441  0.827704  0.24692  -0.486308 -0.410393\n",
              "  0.403931  0.896234  0.994342  0.999567  0.984463  0.806196  0.203125\n",
              " -0.463273 -0.349912  0.409345  0.882694  0.926812  0.548388 -0.255608\n",
              " -0.577612 -0.029078  0.69375   0.965959  0.998599  0.997393  0.943512\n",
              "  0.566051 -0.252249 -0.54287   0.069051  0.733817  0.940858  0.76916\n",
              "  0.123523 -0.54096  -0.338048  0.460043  0.905685  0.993986  0.999872\n",
              "  0.993447  0.881613  0.342833 -0.502293 -0.527953  0.197571  0.635232\n",
              "  0.704901  0.393443 -0.35214  -0.57273   0.071898  0.753138  0.976644\n",
              "  0.99917   0.999991  0.993805  0.88915   0.394687 -0.420017 -0.683342\n",
              " -0.372303 -0.110878 -0.03483  -0.250519 -0.688331 -0.542732  0.219353\n",
              "  0.734919  0.945026  0.996705  0.999962  0.998039  0.960512  0.72262\n",
              "  0.147252 -0.386764 -0.555475 -0.586448 -0.673652 -0.786681 -0.854674\n",
              " -0.642333 -0.112832  0.423214  0.852726  0.990715  0.999893  0.999847\n",
              "  0.995217  0.944217  0.756401  0.445479  0.152919 -0.148108 -0.612969\n",
              " -0.821876 -0.607658 -0.257267  0.116475  0.535131  0.884341  0.992774\n",
              "  0.999917  0.999996  0.999787  0.996204  0.97436   0.908637  0.791337\n",
              "  0.4336   -0.359172 -0.604821  0.004215  0.533514  0.743105  0.872457\n",
              "  0.969248  0.998096  0.999978  1.        0.999997  0.999917  0.998993\n",
              "  0.994645  0.959087  0.570543 -0.364782 -0.485643  0.382008  0.882677\n",
              "  0.976507  0.991596  0.998055  0.99988   0.999999  1.        1.\n",
              "  0.999999  0.999989  0.99955   0.972085  0.591281 -0.337873 -0.460739\n",
              "  0.34378   0.790367  0.947721  0.996029  0.999894  0.999998  1.\n",
              "  1.        1.        1.        1.        0.999769  0.980482  0.697047\n",
              " -0.081311 -0.465333 -0.088486  0.381085  0.823602  0.986267  0.999677\n",
              "  0.999998  1.        1.        1.        1.        1.        0.999911\n",
              "  0.992178  0.870758  0.429997 -0.09022  -0.134659  0.284234  0.799667\n",
              "  0.983826  0.999578  0.999997  1.      ]\n",
              "<NDArray 256 @cpu(0)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "\n",
        "# Code for building Naive Bayes\n",
        "# Initialize the count statistics for p(y) and p(x_i|y)\n",
        "# Initialize all numbers with a count of 1 to ensure\n",
        "# no zero division, call this Laplace smoothing.\n",
        "ycount = nd.ones(shape=(xx))\n",
        "xcount = nd.ones(shape=(xxx, xx))\n",
        "for i in range(len(X_train_mx)):\n",
        "    x = X_train_mx[i].reshape((xxx,))\n",
        "    y = int(y_train_mx[i].asscalar())\n",
        "    ycount[y] += 1\n",
        "    xcount[:, y] += x\n",
        "for i in range(10):\n",
        "    xcount[:, i] = xcount[:, i]/ycount[i]\n",
        "py = ycount / nd.sum(ycount)\n",
        "\n",
        "fig, figarr = plt.subplots(1, 10, figsize=(15, 15))\n",
        "for i in range(10):\n",
        "    figarr[i].imshow(xcount[:, i].reshape((xx, xx)).asnumpy(), cmap='hot')\n",
        "    figarr[i].axes.get_xaxis().set_visible(False)\n",
        "    figarr[i].axes.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "print(py)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5Zc8Y6fi9tfk",
        "outputId": "1891f752-8478-4c9f-a370-7193cee9471c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAAB2CAYAAACJS1kWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlcElEQVR4nO3debQfZZ3n8U9AwpLthpAACUsIghEMIrIKCNggiiIoKiLQaAtOKy1tz7RLo8fjwVZ71NM6Oj1uRxxXWlobRdxXRKRFUFBkVbgYk0YWCTuBJHf+wMxwfr/v+5n8bm7d3Fzfr3PyR75Vt6p+9dTz1POr3NRnysjIyEgkSZIkSZKkMbbJhj4ASZIkSZIkTU4+eJIkSZIkSVInfPAkSZIkSZKkTvjgSZIkSZIkSZ3wwZMkSZIkSZI64YMnSZIkSZIkdcIHT5IkSZIkSerEE9ZlpTVr1mT58uWZMWNGpkyZ0vUxqWFkZCT33Xdf5s+fn002Wb/nhrbrxGG7Tk5j2a6JbTtR2K6Tk+06eXmPnZzss5OT7To52a6T0yDtuk4PnpYvX54dd9xxTA5OY2Pp0qXZYYcd1msbtuvEY7tOTmPRroltO9HYrpOT7Tp5eY+dnOyzk5PtOjnZrpPTurTrOj14mjFjRpJkiyS9zxM3hZ/ZvLG9BVA/GOqvgfrOL4YFh0P9D3RESc6ryxf9pq6fD5u5Gup/bOz60cayXiNJHs7/a5P10WrXsUTXyCKo/zPU9/snWPBL3veHP1/XPwLrty6RLnXRrkPpb9d58DOLG9s7FOovh/q058OCQ6BOo9CleEj54wV1/VxY//tQvwXq9/OuN1h/zeO2My39bTsTfmZJY3svgvrLtoMFZ0D9WKg/aTNYsAqPKZeO1HXotL++sK5/DDZ/Ge85/wn13jbvql3H6h5L/XxXqG8D9Qehfh/Up+ERJU+E+p5Q3wLqv4f6zxv7vmYdt7UmyV0Zn3alnjGrsT1qJ2rXp0CdhuL9ZsMCmpy1dkLbug3qX6vLF9/Iu4bbey4vamuSDGfjmjtRH6D+/Uyovxbqiw5s7Pyeuvyd6+r6J2AzNCee6PfYBel/F8lu8DOt7vFcqO+5MyzYB+p0T94a6tT/koROFf2iwjDUv1qXL2nMyeGrVt99eSz7a9KeO02Hn6HvqklyENRPgfqTj4QFL4H6Qqi3vqT8EOpw0s9/qK5fBJv5dWPXd0N9Zc/fR5I8kPG5xxIaVxPuNk+F+iuhfhh1/H+E+hP3x2N6bFZSuOi3df1v6vL7oJG+2djzUqj3jt+DtOs6PXha++trU9LfsNTQrV+0GnQiTR9jJs3ctoR662qDg9oKVqdd0+dudYjRTFzG4lcKW+06lmjbdB3Ql5eZ1H5Ted/0I6Npp/HQdbvSOafrOeHuRA86ptHGqDFo/cZB0cSUdkED3cbUXx+/napt6bOMqm1pY3SCaeY2kz5343xMgwdP8EFo1zQsUB9I+KiwPg7tOpb3WLoW6FxRPxtFl8VLh+6xtD5ds43bAJ4P7P+TpF3pHOI9lg5qNA1LDUUTPfhwrYeZ1OatcziZ5050PnAO3foGMGB7TIY58eO3s0n6j51OV+urBd4aB71hU78ZtP+1ltGFRfsYhz67IedOre5BzYHtPej3VTqJdMNM+OTCKRz0+21r7jRoPx+PdsWfaSwbtFvivZR+AC+QUQzG1IDwAQf9fpR0066+XFySJEmSJEmd8MGTJEmSJEmSOuGDJ0mSJEmSJHVind7x1EL/jXF+42eOgvo7oD6V3uT9klNhwV9BHV7ElSRnv7EsH/+2+rXgS+Bg3wObv5j3jO/aHOQFixMZPd2cC/UDd4EFf/sGWECvjk3O+t/fKOtfhPXhFW4bZVtMT/+53wPW/cvGdo6lN9HS25ufTO10DNQfqMuv/RQe05yz/q2sn/3X9foL4BKhl9PegHtOVkB9PK+RzdL/f6zp3aNHNLZzKvW1f4X6/q+DBa+G+kKoN14u/szroV7HDiz5fH0tvPfkejNv5j3nO1DvfZ8nvIVqvW2a/nal/5ffusceAPWjB9wW9YOboD5EB9TY9xIKQJlTlx+BtxW3XmkJ70nu68trktzR2M5oVf0VPh6+hD1JngF1ylnZk8buM6H+MnpT8X/BY0qeBPU7of7purxv/UbiZ53Fe75+eV2/uaitgvpEQPNoag3q3/UsNtnpg7CALpwk+Wxd3g12Qv2v9e61iWyb9L9ZZT9Y9/TGdua9BRb8I82M3wR1ehs5aX29oxfNbAv1W+vyW15Rlg8/gfe8AoJhlvX8vav+unn658X0qWn4TBJq1tnU115HcUrPgzrNkWB+lCQnwDfN49aU5Ze/s159qx/XdRi5kyS/gvrqnr93NXeq0LhK3z2T5FlQh1OV2fRl8gSKRTsO6q24hYfr8vEwQ1tUP6A4G9InHqQJUpKvr+MRDdKu/saTJEmSJEmSOuGDJ0mSJEmSJHXCB0+SJEmSJEnqhA+eJEmSJEmS1AkfPEmSJEmSJKkTA6XaVcksQ7DuPo3t0Lvep1IawEteAgvOhjrlAK3EY8I8kHPqJKVdc3tZ/ztIu4N30idJIECgTNcZz0SArmHayQJa8CKovwD3MeWQOtVuLpz03hSTtTbGVLtZ6f88lJj0/NaGXg/1J78SFlB7UP+jXMfD6IiSg2Ho+sB5Zfm0l9WrL4PgpUbIA/blKjekq/66Sfr/1YBGPaon4Qv7Wqgv+FBd3xzqD8J2WhFksymHD9JfXl4ne8y8pE7JevZHeNeUF9N7PaxJO4NktDZJ/z12FqxLCZUJh1UdRfF1EP+yKYQZUfonDt1JllDEzJFQH6rLdN/YEdLuknVP3OpN4BkrgyQpteZOmF5HQy5FL+1P2cInQr01Vfwe1D9Xl79ZJywF0otvg+S6JKkzh+t27Kpt1xXNLZJkGtR3g/pJUN+JEgBft1Vdv5sG6CQX1eVvweowVFBmbXm/nEg2SX+b0b10Xuuf8Cn0MfsOeETUzy6ty6saHecJ82ABpVfC3HvKGXX9kI/jrhdDqt1Qz9+7mnNXYzGlnFF6ZJLMpuQ+mhZnm7q8DOZOFCd2Hx9TlkCdBhJI/j3+J3X9ikanXQr1au7UhSoReAjWfWpjOzSEzqZIvxNoNB6uyz98Tl3/Lh8TXojH7lXX99qprp/yu3rz/8K7/hnUe5OeB2lXf+NJkiRJkiRJnfDBkyRJkiRJkjrhgydJkiRJkiR1wgdPkiRJkiRJ6oQPniRJkiRJktQJHzxJkiRJkiSpE62M3D6bpf9J1c6wbiuefSGlD75uJiw4DuoXQ/3cuvzI5XxQU2nfEEB/1u1lefHN9eonQbJwktwB9SqGtqsY7w0Bn3pS7DaGY07nnUB8OIQLTyqbpT8OeAjWnUKZ7Ukj1/ZLUP9KXb4Fwq9781bX2rvVShD7/Rdb1/VT6n0f9oF69Ssae74N6g8XtZHGdsYaxVZf2/iZb/6+rh8GkcBbQpOMQCo3Raxu2kqSftsP6vqx1M8X1OU9flmWd23seg7UN+/5e1eRwFXUM3y6HNLYzlE7wILToD5cl+dCRjrFikPvewzFiu8NdboP/Lwut/4VbTXUH+n5e1ftOi39x7cjrLtPYzt70oSLpkj701mhFvxYXb6uMXeimOmL6vJd19T1n8JmKM454XG6mlN11bbrCqc1wWlKjoT6UZQH/kbaA0S5f7CO106S7/+orkOz0hBS3hc3BiuTrOqp0Vz9xsbFtfs3YMGm0KfuhTrcFmk8zH18TNmn/v6SD72jru9KE8Q763Kj0Wme0jvNxGnneto0/WMxffujMTpJsltjBxUaQ99cl2+7sK7PaBzStFfBgrOgvhjqML7s/IvGvqE+Xr/dslmSKT21ubDuoY3tLH4eLDh1HiyASdK7flKW735LvTp9DUqSha+ABcfStxFowN3q8X67xr67aFd/40mSJEmSJEmd8MGTJEmSJEmSOuGDJ0mSJEmSJHXCB0+SJEmSJEnqhA+eJEmSJEmS1ImBUu1mpf9JFSWwvKgRNJYzacHJUL+hLj8CCQzvgc1cwoeUxffW9VdBZMReU+v66b05OY95DkW2JLn6N3V9aVFbHU7W2NjAGeTAHbxc8Qcwvo72TYEUG6NH05/kQxkI1zciFRZ/GBZcAX2GdgJpRn2RYWudDlFpSXIGJVourMtPrVPt9oCttFIeGlfbuFmT/sQ8asKrG9uh4JvLoL4tNAmlMtH9YSeKG0kwSJQzGS+tyxA2AlfthDAj/fdYOh3HtDZ0CtSfDXVIXqJrfQjqzRQgSrWjOl2ckCAFmZlJkhVQ7w1f6ir5bHr67y2jSbXDKENKOcOWgvHzcugdEHaXJCOfqOuQbYrpdTANyjLeNc6FqrFwvFLtaA7RSnykNqcQSkyvW7BTXb+0TjN65O18TJ+F+k1QpxSysZxTUTplFx5M/1i8HNal+2WSzDkP6v9e13+7sq7TjAeCtJvpZ6fDeD+HNrYr9ULozZS0F/w219eXexMFx8rq9M+d6LpqJjLS4DMMdZiPUJ2m0c1EbppXDUGd7rEQwYnf2SaAKhGYTsfTWhs6mhbATOyWOr0u0O/pMti79czkxbSA4grh28Dq75RlSppMuA/03k8Hub/6G0+SJEmSJEnqhA+eJEmSJEmS1AkfPEmSJEmSJKkTPniSJEmSJElSJ3zwJEmSJEmSpE4MlGq3ffEDR9LKGMeR5OB5sIBe6/4/6vI5dfnud9Z1SoVIkr2/XdcXUgTSW+v0OozJOpH3/Xw43upd+Y8muY43NSFRqgkEJ4xtbNhkiqkb0D3pf7JMiSJfbGznGT+q63OhvgK2QwEaFMi0YAkfU06C+JXpi+o6XFNDsPlZjV3T5VklfnSVpPRokik9NUqmaKVgUvcYgjqFah1FsXaUYPr3dERJpr4dFsCZ/8/P1HVIMaX0rISv3d7EpvFMP1sM6y7E9L/wjZnuT1fU5W0H3MziVnTXoVCnfn491OHWu6Kxa8rHXJ9klkFslv52HYJ1qSslwdBOjuGkOdWdrb30a0RkTYGLZO4f6jolI9FUqzV+UZJnlcTTm2TVFUqdgjtTkuS5UJ/zUljwAqg/UqfXUdJzI6wQ09IGuf8lnBjWSlKCYLdxbdeH0z9/omvxZ43trID6aviQdN4pTZDGNhqjk2QO/coBpmPCOHIj5Px9i/dNgXe957arBMNH09+uK2BdOudJcjh9oaR7Lw0AL6zLe9O9tDUvpjRb2ha1EyRQtxJGu0g/G8Qm6W9XGqtmtjaE3z8hZ5C+2EAH3HsI1v9LPKLkeS+BBa+C+tl1GToffS9MOC14febE/saTJEmSJEmSOuGDJ0mSJEmSJHXCB0+SJEmSJEnqhA+eJEmSJEmS1AkfPEmSJEmSJKkTA6XaLUp/csVz6NEVxXQk4egEiNb5MuSdvK8ufxi2fnXjiOAl/nnr52DBYVB/PtQP4H3vCTE2exSBESuTfIM3tVEZPNWOLtdVvJOuojE2AlUqy1JY96eN7UBuCSa/UfPtCPV9acfTaEE4ymULyISBOJreZIb/u5nGrim1qLqeu0rwqNBnaXUBCjt5BtSPoqH7vfQDlMbxLjymhOLaPlGX6QKF+l2NPW/oZJZZ6R/lMA0LE4jCkUbbQJ7LovoeO+WIevW9Kd6J7n8Jp7bMhqvt3irXNRyf1bChbwOPpv+aoVQvSmpLki0hWIcCd7KA0utghFsMA+sxjYOCTR0ME5XtYCJG42qrr1HwIfXjsbZZ+tNF58K6+zS2czxNhiilajr043+t+/GyC+vVr20cE90bdoY6JaSOJm2VhvQqYWlNkvsb2xqtKv2Mjrl1HmnORfdr2geFZ9FcpZmO+WKoz6P79Yq6/JW6/MNGg9C56t1DV/fYVenvs3TOW98Zb4R43N1/AD9A9+t/GLA+tZWPuU1d/uXldf38uvxDuA2MJhG49947XumiCfexVjrfEngMkWPguwV9T4G0Quywx7ey9t4GdYqz/UJdhhTD1vi1Auq94cKDtKu/8SRJkiRJkqRO+OBJkiRJkiRJnfDBkyRJkiRJkjrhgydJkiRJkiR1wgdPkiRJkiRJ6sRAqXa7p3ghO8UfLRnF0dwPcQDw5v2vrqzrl8Hmhxu7pgSFK+G1+E+n18AfBXWKAkmSp9XlRUW0x0ONzUxUlHaCyWEUb4OXayPDBtqPUo42dPpR16gtRmMO1CmT7ECozzsEFjSSIPHioQgZqFPiDiYuhkMsqkPqKplldfqTWeiUtELAhqBObYgLMEKHEievpB9I8vvB6hTsAclui2jzSWZAvfd66Kpdtyr2NUQr08EmjUTIHeryfnBDOx02sznUj+NDyhMghpY+4UJItYO4LdhKkg3frg+nf+z9A6z788Z2joFUGoxSWw7xRHOhTv8USe2dcFwbnPRdt63rp3+7sQ9Ad/4biloX6Wdbpf+ULYR1D21tiFLGDoL6nZD0fF5dpmuqlY9Fwc2DptoNQ72VGEbHW03n1qSdVDpaK9N/j10B6/YmPD0e3X9prjloOi3d/o7GI0ryRlpwMtRfW5chaJaGqSS5Feq9fbmr9LNHs+7telNjOz+G+u4Xw4JXQ30qxde9COqt3FNoWPgO/bvv1nUK5htu7Jnm0r3Xc5ft2jsW07jQGnue8ylYAPetgZ914LwNZ92NZdfU5a/W9/f/gJBbSodNOE2zd65kqp0kSZIkSZI2OB88SZIkSZIkqRM+eJIkSZIkSVInfPAkSZIkSZKkTvjgSZIkSZIkSZ0YKNVuxxSBY0+ClSllJQm+a55eNQ8pAVfA6hRstYIPCN9+fwf9AL3qnR7lDTV2DrEU1SmELJoJjU4JJodh3B1drit453DCKDlkMtk2/UkzFEBEwXIJp9tQOlH2hTolYNIOaP0kmTKvrt92e12n/gowFCzclaswxq5SEjdNfzLLaP4VgU4LDcWLv1TXp9FAud8FdX0PqCd8/ewFn5CuwxPr8vGQ5JIkl0Gs2c09f++qXVenvx1X0MpVdNdaV0H9GZBeR0krR0B9e4iWyzl4SMmZUIc7+YARnK0+Sx+v91bTVbuuSn8KDHWZnzW2swUkMh70T3V9y11gQwugTvM26mOtbdEl8qy6TCmpL2yk3dFc77ai1kX62fT0X6aUP9S6x2I/o5NCYxjEwS2E1VvJZ1PpgCnWDm4m+0E45VxIWGpsqmzXrvrsmvTfYylFsTWfbCXkVug+TuMbhLfmwP0bO3n6a2DBrLr85SJiO8klcA+i72YJ98H1SclaX9R+re9b+N2QBiWcg9IAShMhytNLcj8MABAzSFuiNL8VvOfOEmHXVZVCSW3008Z2PrOyrp/4jro+9SmwIbqXUrP+xTAfFI4859blT9ZlClyse3d7z73jrql2kiRJkiRJ2uB88CRJkiRJkqRO+OBJkiRJkiRJnfDBkyRJkiRJkjrhgydJkiRJkiR1wgdPkiRJkiRJ6gTl05e2SJF0TznFW7aead1flyGG8l7I+hs4tbKBokopzXbgOOLWQUFsdBVPuaEjK8cSxsz2XWRr0eVKgY/B896Kv50sDkgytadGgeZ7trKeXwr1Y6C+606w4DCoPwnqQ3RESa6uyzt+vK5Df509va4vgiEq4ejRKiZ4FW9mvWyW/uhY6jatOGeKNv4+1Clmd7sf1fWtob6QDymHQpvkTTD6vQrWp8vtRN73QefV9d743VVJfsObGbW70z/KwZWefS/j7ez0TlhwKNTnQ52i07enMXeIDil438/36vIlsDqckCpqfS1ISB43m6f/Nk/9tTVVoFPyM6jPuKWuz4E6XQaUGJ0ks58GC46G+lMHW3/3m3nf+0AnrELFVyVpbGpUZqW/v+4K686k21yS7AF1mqgMQx0mrEt2hPWPwyNKDoL6TKgvg/qiunzoB3jXV0C96jNd3WNXp/8e21p30GUw7c/mUN8a6s+lHf93WpAkZ0P9nLr87rr8FdjKcGPPXcSzD2KTrPvcib7eJtwe2RbqOBG7EuofhfrFtKHkBqjDOELX4GjQN/7eelft+mj62/UeWJdOU5JcCPVbob7oGqjD+gf+ERa8pzWSDdfl+99flh+4oF6d5pIrGnvu4ruyv/EkSZIkSZKkTvjgSZIkSZIkSZ3wwZMkSZIkSZI64YMnSZIkSZIkdcIHT5IkSZIkSerEQKl296VIaHhwNJseqsvw1n9KhaCnZpREsBUfEAat7DcLFhwB9SfsDwsu551DGkiV2tfIb5uwKDkBExUw1Y4WNM4KLGqlkEwWz01/WuOer4CV/6Gxod2PggUnQ53ixBY2dlJp5VRtV5e3hJijZ/+grl9bl4+EdLOEUx7uKGqP8GbWy/T0j3+USAVnKgkHrVCyVpUWlQyeGkbBL0lyM4SfnfZF+AGK9Xk63CEO4mzQvaHde4+3q1TMu9LfrpRY1vpXowO+XdeXQH0B3RypKz8KN/7nfKlxVNCfH3pzXf9wXb4S4mUosaWx5zzQ8/euUmOnp39GtAOsS2k4CV93lLT5K6hTf6VQXgquS5KX/6KuT9sHfoAGJEpeo0EnyZNguK/C3broszPS3644trUatjVIV2jgpv5KDfiMxj6GBtw3XdCUqHUR73oLaNcNnfRM88bWfHLQ4+tNIl5rN6gfuwssOPw1jb0M1eXL61TgH8LXl5/A1ilNLNnwidKbpj/9jFLNW91yMS3YG+r0xfSRT9b1O6C+gnacehKaYHD0HnDTpPRU/GqWsU3IGyv0zZBOU5JcBXUK7aR7Jt3+DsSvq63s2N5c5T/5RF3+OmxlGOqt+XsX35X9jSdJkiRJkiR1wgdPkiRJkiRJ6oQPniRJkiRJktQJHzxJkiRJkiSpEz54kiRJkiRJUicGSrX7TZLNe4uUOHJ3I89p9s51fb86OmE2RM4dCm/kH4LdUmhKkrySFrwL6gc/ExZAfMDNjVS7i+tyFbjVVUpWl+it+IOn2k0ffOdwwv4cUu0OSDKzt3g6rLz7GY0tnQB1uNaxB1Kcw6oB60mdW5RgrM/+N9T1k+o8qC17464ev4cL63qVINVVCuWs9PefPWDdAxrbGYI6pWTdBPUqgTPh0FMKRko4/CVbQ51iRShFcc7NuG8Kd+sdkrr6F5t70p+4Q+ccA2WTwNWOyYe7wcaO+0Zd344utqMv4IOaAsksH6vLd0NAHhwSptEknGrX+7FHGttYH1ukf7K1K6x7dGM71DeovSkREULD8L7YSr3BvkATLooQpgnBQt73ENRb48tYekKxL0rI4oEtjw3olal9d/DHLL63rg/BdhZCvRUxRsMkTN+zPRzrXDjWxs3xLqhXaasb61yOLne6FI6kDdF3lJzT2DvEYb2hLp8PW6H7/saWvk3jRavLYkgl3Rupwb8KdbrR0Two4ZTKfevykq/U9fkw4F/T2PVERGND6/qk79g036L63rQDnJAfTAuSfL4uf7YuXwFb+SPUx/u5gr/xJEmSJEmSpE744EmSJEmSJEmd8MGTJEmSJEmSOuGDJ0mSJEmSJHXCB0+SJEmSJEnqxECpdlel/+3/w/D69IX0Rv4keTnUdzqprn/gvLJ8GoU2UMTL0xrH9LdQPwqOCZO+IGLi07zrL99f16uUrFbO18Zm7NJIBrqM/2xsliKtAxPAKGoo4RibFVD/NdThQsermtZPkmVQH4b6NnV5H8hvg3C8JJkDY97cYlMP8WbWy+bpv+oXw7o03CbJNGp2CCK665a6Xo1VCaeH0LEmycJDYMHboL4TRblAltkw75vS/HrTlFphUOvj0fSn2t0D67aSWe6AOqUQVWlRCedWbkcnigMDk4fhh75elyHsFa+13zd2Teewtx27SrVbnf52pcSkXSl6MEmeXZfnwQV5KAQJ3gWxdivomPrijB+HklLPgvrsU2HB1+ryA5TFw9d5FUraxdzpofRfQ5TIhpFCTRCBdOCVdf3+AXdCJzDhdOHt5w32A9fWN5PfNTosTeGrLa3hzUxo1KXo3ngqRa6+jO5/MOdJkjtfX5Z/9qN6dQovp0SvjS1pkI639TkwfJvm2NR+f4A63eh2ox039k1JeDD/m9MIYSc0J+rtn13dYwfRatdBk/Dot3fwG9ULaQF9z0pyy3vL8u3wXWQYNjNR0ib9jSdJkiRJkiR1wgdPkiRJkiRJ6oQPniRJkiRJktQJHzxJkiRJkiSpEz54kiRJkiRJUicGigO7Kf1Pqj4K6777TY0NHfRvdX2X99X1wyHZ4/B/hx1QXMbBjYM6GeqU6/PPdfncOv9h+IO85/OhfmtR21gTPCqUiMGxMCsG3wlET0yF1TcdsD6R0zt+kWRaT+3Qb8HKu0OiUJJkB6jT8AGRSZhVQyl4ENmQJMvg6qFrhyI3VkCdYr6S5JG6XCVGrGxsZn2sSf+1R/+KMK0RlpH/BnUYcufAaT+c4tLooPZoHNMu+8CCF0AdYmGu+0ldr0NSkyQ/hnpvHltX6aJV+hklkbTGHrrcqTnocsf7DfQBChJMUt/QkuSaukx3ccrtqpLM1trQ4/Td6b+HYAAg3v+SUNd4PtTh/jcHTuIcukBaMZRTzoAFJ0J9uC4v+0xd/y7vmtK2qhGhi2vgzvS367W08iWNDUEfyOELYQGc2+k0WqyA9SlSK+FRDjr5dRfU9ffXZZr3Jsn1UK9uPxMhJaulL1n4T4agvi9tiNIj82qof4V+IHlnXb4IVqfww67SXbtUJcfS/a/VO2j8nkPj90KovxTq20K9lWq3F0ysbodRCb7Y0L20dY+la6F33J3o/ZVQP94O6kfQho6mBXfyzuEeeDWsTnOkdU0e7Jq/8SRJkiRJkqRO+OBJkiRJkiRJnfDBkyRJkiRJkjrhgydJkiRJkiR1wgdPkiRJkiRJ6oQPniRJkiRJktQJykMv3Zn+GMpvwLozKAs5ydmUM3jh39f1vd4OP/BRqD8R6q2PS3m2EFX63u+U5RvfWK8O6aVJkp9CvYr43BijKCnCEZO3MT75X6A+nXdO6cJ/Br6WZPOe2qGvp7WpJyc5DZbNXAQ/ALGgt9xb1y+DzfyEDwlzRFdAfQbUIW6cs86TK+Hj3VDUKHV+fd2d/n81oBjv31GMfZKdqBPuDrG8Obsu7/10WH+Id46GoX5uXb7q43X9dXX5qzTUJ/k+1Jf1/H0842fHMgaexmKqY3zycqhf0dj5TXX5btgWRXjTMbWivekcjlfU853p76+XwLqfWcnbOfXTsGAfqB8Mk63tT4MfOAzqC/GYGMS5j0Au/H+ty99s9NcfQL0a1rros1W70nzuU412Pe0cWPAUGNu2ofH2ZKgPQf16PKbkf9Xlqy6o639Vl8+9rq5f1NgzDS9VH5/oc2JIrM80qC+gDe1MC66EOs2Xk3ywLv8KVqcxdyzvTeNldfq/x1bftZLkt43tfB3q+9EYfQrUd/+7un7CaOZUF9fln9azw7tg7k3T6z829jxZvmpRf6X61lCfPWvQPdOFE/x6Vn3nSPh6nij91d94kiRJkiRJUid88CRJkiRJkqRO+OBJkiRJkiRJnfDBkyRJkiRJkjrhgydJkiRJkiR1YqBUu0fTnwYwDOt+rrGdWyFl6W+eWteXnPT2esHrob4/PE+7t5Fr8kWoQ9rIp+AzfAE2Q2kRSXIP1Ks30E/0BI8KpQ3RG/m/ACk2J77trfWC3XjfN15e1ynMi1LIJkoawCC+l/4khoehCxx3Fm/nqDfAgj0a0W8VSLX67f11nZI1Eh536FqjUDuqU59MOD3u50Wtq+vmnvSPxZSm9J7Gdl4DKZx7XgGf8kyIZnnmVNjDdnX5od/xQX0L6p+sy8surOufhc1Qcl3CY1Lv9TARxuHWtUX/okRpJ72pfWtRsOR8SMN5eiPV7nbonJB9hvdMStZppeq0Eu/Gw4Pp7680jny4sZ1b4fyeeUhdn/0qyH07BeoHwI4p/TPhYLTzof7+unwuDLqQoZYkuQrq45UIvDL97UpjyKca23kAmuO1u8APvPWv6/pJUJ8P22ndZOFCXPaJgVbHkOLhxq4fhPrGOCemOSWNxVdB/cR3w4IHP1TX6T6a5H/CPBCmaJMmsYzQ52uEs2Mq42bw3fDs/eEHPgID4stgTjXSyEqGTvjQmXWdLqlqLptwaHSycX5HqtDnoDkEpe9eCvezg8+AH9iMv0/9Gm6C/zHgMdF1Pt5t5288SZIkSZIkqRM+eJIkSZIkSVInfPAkSZIkSZKkTvjgSZIkSZIkSZ1Yp5eLj4w89vq+6iV+9GK/1suq6NVo8I7h3Etv9cIfgKO6l48pD0EdXsJHq9OhNl5rjuewdb7Xtsn6aLXrWBr0GqEXS967EhZQY4QvkVVQH6QtxlIX7VqdX+p7DzS2R91p4DfSwXboJZt0HST8kjzqfzTQUb1xSQ30Avq1tbFo18dvp9oaNUfjVZSDj7l0oeBFMuAAmnDDwzHR9UPXCPX9hMfp3k83lv318dsZq3FmwNbAc0JD7qC33oTbadB7KV3nrXO3rud1PNt10LZI+Jqmqc2mgw74tKHRDCJ0sHBqB70OknXvr4+vdT13Gk270mfH/kTnljoZtSu1XYJtTrugsYI+90ScEz9+O12PxTSO0XnEbKRR3Ojoeht0bO1yXjwR2rV1jdK5wjGadoxfeOAHWh8AGpbam661yXKPHUuDjut4i6UbWuMD0DA96POGLvvxQO06sg6WLl068qft+meC/Fm6dOm6NJ3tupH9sV0n55+xaFfbduL9sV0n5x/bdfL+8R47Of/YZyfnH9t1cv6xXSfnn3Vp1ykjI///x1Nr1qzJ8uXLM2PGjEyZ0hseq/E0MjKS++67L/Pnz88mm6zf/5S0XScO23VyGst2TWzbicJ2nZxs18nLe+zkZJ+dnGzXycl2nZwGadd1evAkSZIkSZIkDcqXi0uSJEmSJKkTPniSJEmSJElSJ3zwJEmSJEmSpE744EmSJEmSJEmd8MGTJEmSJEmSOuGDJ0mSJEmSJHXCB0+SJEmSJEnqxP8BWLLt+bFEyf8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[0.16692238 0.13639154 0.09987726 0.08867751 0.09159251 0.07701749\n",
            " 0.08975146 0.08514882 0.07625038 0.08837067]\n",
            "<NDArray 10 @cpu(0)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "px = xcount\n",
        "print(px)"
      ],
      "metadata": {
        "id": "nyJfd9RFGbDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d03564c-6ca5-483d-c680-f043b7b81b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[[0.00215255 0.00112486 0.01019217 ... 0.02502297 0.00671088 0.00212635]\n",
            " [0.005289   0.00112486 0.03002939 ... 0.06644479 0.02017692 0.00385446]\n",
            " [0.01586523 0.00112613 0.06701548 ... 0.12914951 0.05329801 0.01019015]\n",
            " ...\n",
            " [0.02425583 0.00188609 0.12443396 ... 0.00195336 0.01259392 0.00347565]\n",
            " [0.00619167 0.00133937 0.08563295 ... 0.00180939 0.00398494 0.0021087 ]\n",
            " [0.00171074 0.00116585 0.03956724 ... 0.0018019  0.00220427 0.00179709]]\n",
            "<NDArray 256x10 @cpu(0)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "\n",
        "logpx = nd.log(px)\n",
        "logpxneg = nd.log(1-px)\n",
        "logpy = nd.log(py)\n",
        "\n",
        "def bayespost(data):\n",
        "    # we need to incorporate the prior probability p(y) since p(y|x) is\n",
        "    # proportional to p(x|y) p(y)\n",
        "    logpost = logpy.copy()\n",
        "    logpost += (logpx * data + logpxneg * (1-data)).sum(0)\n",
        "    # normalize to prevent overflow or underflow by subtracting the largest\n",
        "    # value\n",
        "    logpost -= nd.max(logpost)\n",
        "    # and compute the softmax using logpx\n",
        "    post = nd.exp(logpost).asnumpy()\n",
        "    post /= np.sum(post)\n",
        "    return post"
      ],
      "metadata": {
        "id": "9PtUvaulGsLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "\n",
        "fig, figarr = plt.subplots(2, 10, figsize=(10, 3))\n",
        "ctr = 0\n",
        "for i in range(len(X_test_mx)):\n",
        "    x = X_test_mx[i].reshape((xxx,1))\n",
        "    y = int(y_test_mx[i].asscalar())\n",
        "    post = bayespost(x)\n",
        "    figarr[1, ctr].bar(range(10), post)\n",
        "    figarr[1, ctr].axes.get_yaxis().set_visible(False)\n",
        "    figarr[0, ctr].imshow(x.reshape((xx, xx)).asnumpy(), cmap='hot')\n",
        "    figarr[0, ctr].axes.get_xaxis().set_visible(False)\n",
        "    figarr[0, ctr].axes.get_yaxis().set_visible(False)\n",
        "    ctr += 1\n",
        "    if ctr == 10: break\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "7CA8G3mRGv2J",
        "outputId": "0ed416a6-0519-4080-8ca9-b9d28e0f68e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 20 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAD/CAYAAAB2IaD+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmfElEQVR4nO3de5gcVZnH8XcmYRKEGQYJuUxIiNyMBghLyMVFECFsghFXUYiCCBJNFPCy4bLiohMEBZRVEBAvCFEjErKKrCsGYxRcEIjCsugickvMSIDIZZwBAsFM7R9k6Hl/dZLuPnN6unv4fp5nnuStrq6ueftUVZ/p89ZpyLIsMwAAAABIqLHaOwAAAABg8KGjAQAAACA5OhoAAAAAkqOjAQAAACA5OhoAAAAAkqOjAQAAACA5OhoAAAAAkqOjAQAAACC5oaWs1NPTY+vWrbPm5mZraGio9D7VrCzLrLu729ra2qyxsbQ+GrmLy5sZuTOjzfUHuYtH7uKRu3jkLg7X2Hi0uXgl5y4rQUdHR2Zm/Gz+6ejoKCVt5K4feSN38bkjb+SO3FX/h9yRu1rOG7mLzx15Ky93JX2j0dzcbGZmw80stu82JLBsmMTaH/q7xC9EvnYq2eZ96M1HKWJyt43EIwPrzJX4zENlwfck3n6aLPi9D3+2wcdX+fCZn+f34YYice8r9JjZU1Ze3szicqftbHRgnXdL/OkmWXC2xG+VWBuq/OIPfNHHZwT24W6JXwqsY9a/NreHFfKxY5HXWy/x84HtbmkfY+l7pSej0DnjNRLvIHF3n//3mNkjVvnjNcZwifUY30fiRRKP+5ws+B8fnnl9/jV/IPHW3s+BOteNkVgPPTOzdy+SBZMl/r4Pn/4PH18sq/9E4sfCuxZtoHIXQ/P9CYlPPEYWyEG56Boff1tW7+85YqByp+eWCYF1vinxpM/4+Olzfayp+6PEm4rs04jAsqMkfpvEl27+9yUzu8kG5hqrQufpAyS+QTd+ucQX+fDER3y8UlZPeS2qVJvTa9N0iU8PPGff98qC2RKPk/hZieVz3x1yLjxfVv/fwD6U8zm71NyV1NHo/WqoweIbY+h5+nlNY31OrXxBVc5XZTG50/VCB7J+UGnRd7JF4u11BXkV/QQnvZ3QSXJbifUVcu9nmV8xVip32sFt0SdpcreXWH8x2aCuHjrIym3bMW1uiBV+f92HTOJix6JZ+uNPt1fKPugyfX9D73elj9cYxdqp/rFBT+Mt2kblCdrGQ69Zyu9X6dzp+6mnIbPA77qdxPK764eQYn/QqtT7XIvtTn93PYe3aMMr0q4qdY2uhWusnse1HWo7K3KFLbpvofOd5rtI0x+Qa2xuG4FluY8jupI2PPnlc79XCa/ZX6nbnL6f+jtp+zIza9E/euoJUZ+kF3J5EW0vxdrolpYVUyx3FIMDAAAASK6kbzRS0D9KmZm9SWId/fMniVdI/ITExb6arBX615PXSjxV4g8EtnHkPFlw5btkwdck1i/EHpYN/kXiNS7c0e7M7cOH7/qZjw/0jx/74sv/vmRm8g1exYyS+F8C6yzQ3J0q8eMSa8ObIPFZPpz4dh9/Sb8zNbPjJX4kv0q/fd4Kf9GYrd/jSnO440Ufh75S1bTo8actTP+Co+1cvwWeIHHoy1h9f3eXuO9b9ZyZvSewjWrQXOjoH2lCdvgbZMGXJJ6zr4+X3evCUdfl90HPO6mHwpVC92FPiedqYszM/lXPbTJe4B/8AbrTBf7hCz/l49fIGLIrZetPB3ahXulfNP9Z4g//myw4730+vtYnq2lxgp2qAXo6fH9gnX1kCKyd4YcJ7PTVLhc36QmxCD0nvCWwzoU64llOaL878+V/XzCz/yrv5Ssq91lMT/YnHu3jo5a5cK68Qb+Rp9fiMarXq1kSX6UXr1WBjYyX8XkmH6psJ4nlqnvYf/pnz/MXjktn+tUXBnZBP3c/JXHMdYNvNAAAAAAkR0cDAAAAQHJ0NAAAAAAkN2A1GqG7oOit2hZ8RBas8+ElfviZXbb11WvKNlao5t9NHlugsY7L/EZgg/t9VBbo4Ga5Ae6qX/tYiwL0fpqT2mSBju41sykf8/HNl7rwo5uLcJ6zytVoFBuDvEDvOWhmNl9iuf/sj3/hY61O0XHlJ+kQ8h/53O03P98yp8q9Ezvk8RTj5w8/ps9dZJbo7SwOc9EM+7OPH7svv0Et3NCBs3+VWAetvlFiLcoav78s2DW/D7aLxH68/uyvX/3K/7s2WHgQaoWF7mAzQeIvSDzjV7LgEPkb0LIeH3/C12Q881X/8O2BfajFGrZcHc7rQ2v5tmn/IjeH1iKLz0osx3v7L338Jxlbf1NgD6p9a/VYehbXWiA774OyQCoFvuhrNPSQl1ZZs7SdHSnx6VowamZ2htzy56e+JmOZtBs9hxc73vTW66F6wtx9XeVSMnxzjYbefGgghX5PLVdZL4fwSGv1C1r855lZdoWLtTKhVmo0hljhc51+LrhYV35A4pblgS2OlbhTYv3IPlHivX14mL+GTvyFL0i9Ue/1b2bL/ubjK+TxvmffzMxkYoQgvtEAAAAAkBwdDQAAAADJ0dEAAAAAkNyA1Wg8H1imY98X6AI/5N8+IQPyX5D7oetYMh0yXk1jrTB2+xx57MjLZcHJOm52TmCLS334LV/gslHGJV/tw9x40p0lPkAGgx64i2bX8pMUyJv81/DiftHx73tIrGPf7dzARs73YbvUZCyR1Tsl1ly98Xofz1gvA2kD82i0fTO/LLVHriuMTd59z43+wQ/6OVBsvBRQjHlrfoNjnvPx7IdkBR3JrtOYjpBYazC0/iI0YP80iWV2j7F9WnrKhlcGvV26mdnHJZ6hB+QhUij0sL//+QNSa6SnDKlasAcD+1CNeTOU/mUrN7+STrZiZmZP+lDmCDlJptXY/0wfn6rla1LedtoiHweqk4L5rDWh2iAZsW07aUM0SZZ92kW3/Y9/9H5ZuxbrfszytXsyfYB97XWyIDRc/g5/AnlY5kf6iqxe7POGtnWdN2O/TwaetL18Frjenzh+v/lfObtXnVwpcvWzI3PXCj9fxHbScHf+g4+1xLRa7bDRCjUaB8hjLfrZo0WrikNXCjke/0+u0zr5yl57bf352soOk2rZzm/n9uDoa/1rdsrUOn3n2egxM1+5FMY3GgAAAACSo6MBAAAAIDk6GgAAAACSG7AajdB9yFdIfJaMBz3/U7KCDEz+16d8/MjPfaxzN1TzXuhHWWGM5pE6du9kHbt3isTfz2/w3mU+/rwPpXzF5NbxJkMec3UIOp5017/kd2G3i7f+nN5x43/PPzWa9ox15oUmHcIf8PvFPpZql9xYWx0WOU7iXAmGPkHnnwi8RiXMt8IBPnWRf+yNEu8vI9P3DoxU31Ynw9Gb6Ovjw6VI4oX1Pn5JXkOLX3I3/Tezk7WVPerDz/X5/wAN3NWygmMD65x0oiw48cOy4DYfzvahngpvkVjrL2p17Lw2mVzdSHfoWVK7c8BaF74g8ytpNdk2cvwtkImMpkjp0J5SEmJWO2PCt0ZPO2b5qWtM56rSGV42+oIzvU5UqeypJH3nqtKynCV64Sil2MSXDeSm5NE6Rz0z6elQZzzIlQ9+RWfYMstdmdt9WIlrbAp6XHfm1tAlUo93hA93lYb4W3l2tY7HYVb4TKKfRWyeLjhM4j/rCmZ3SU2GPOVhmeNi99fJ5BzXfsjH0y4oslOT8vsw0++D1jvF4BsNAAAAAMnR0QAAAACQHB0NAAAAAMnR0QAAAACQ3IAVg4c8LbEWMO98q48XStGfTuh3jtQTacHQn6x6Zluf6cvm66NauqaV16PzG9z3Yz5+wCfjhCv9wydIheSNUlyl5ehav6wTgm1pWV+9hZ9ZkfX6Q+uHTevpAjNt3SOxFq5pce9UiXWKmwZtyDse7uOr9LYHhYmWemmRbAp/tEJxpJZ2N0ncLPEOge01vbj112uURDbJRGpasKdF9edKs989MNFhbvK2lX72xe/8rvD/DaGnJ6BFt9o+ztHD2czs6iNlgfxyF37LhRfJXIh6PNZL8XcxWlBrvwqtJa1RJtybJdcFPX5z02Ld4MNH5eCr5k1DUttJF2hFsn4EkPOl3G+lpvWdFDdXaL1W4qav+/iHuSp5e0raxall7o+2wyk6P+mP9Rlabm5mK/yrXiLn4N6bFFTi+tEfxYvB5SYeesOHg3w42s9fWjO2scJf63OfRXIf21olDpTwT5EJ+E73xd6760cJfdHc3RoelrhTYr2tiJl914d67el7fiz1sx3faAAAAABIjo4GAAAAgOToaAAAAABIrqo1GkqHui+R+P2f8fFImddutAzMfIusr5MumQUmjKqQm60woc9+OlfXh2RAog7uDM2YsofE27f5+GQZ83iyHw/4tnt8hcXbZAj5l2W8vNbPmOXLH7aUy0rWaGibsTUSvz3/nOPf4OOxf/SxTrR0oI65XyVx0zOyYJaLVkitgll+bHolxthvskKNhm5f36vnJH484vWGSKx/xdCajI9LvLsWv0yROiQzs65FLlw/0z/8jT7/r9QkVno4/rOu8MPQs66RWAoF1vjwzbK2vj+/kFjrz3T9WqHtcJ3Ev9UFZjZVx3PPPtqFJxznJy89Qd8gnbXuPB9eJmU/+akq67cGJveXxIaWrT9BJkysp1qg6VaoPZsh134bqxWbB/jw3TIw3cx2ev43Lj58W70wSzXPBhkgn1tfazAWFHnczN7pQ52EuPcVK3mNjaHt5G+5NXTGRPkoKvUsWkOo15qB+hynXrTCMfY7eWy2foA9XushZlmeTM58tkzkerbWXOhHeClUzk0nLFf2rnxt0nqZ9Pi/5fG+uaZGAwAAAEDV0NEAAAAAkBwdDQAAAADJlVWjMcQKY771XvKvCazbV+je5LpM7wWts0nIVBDWvlQWzPPhkTJOU8c3mgXG+FfIEivk5D657/s4ibVGYLjl6S2aJ8to50kHy2DnL8gTDpzm445OFy68yt+/+SDJrZnZyRLrOPFKjOfVNqIjb9fL/bZHHhvYyH2+f33oY7JVfZGxI2XBNyVu9eEdvojjzsAu5G53PQjo+60jlD8o8dF6s/uTdA0Zr2pmNsmHUqbl2mClxi3r8ai3x7fddZYSsz6z6GwmY2ev8HOvzPiyv2H6DDl5nf4BH+tob63hMMsNv68JnRLfGFhn6k/v9QvmyMlsSas8Q8YhL/uJC38kNRnXy7P/GtiHeqXX4XzrHbrVh/PPr13bWp9rZ27Hr5J4pcQlzJ7yR/m0cLs8rpMjzZT152hhZacPF38v95LnyIVC6yJ7z7m1VqOhOnXBo/KLjZVCxlYfhj4D1YIXrfCZ+CZ5bL6co0ce8F6/4A1nBLaoBaETijy+t8QjJNZ2LXVAsktmZlreJFM6ues8NRoAAAAAqoaOBgAAAIDk6GgAAAAASK6sGo0ZVqjNkNvX2/4S7yRx6N7kOr7+bol13ovfSGwXS/wRXyly6A5+HODY/M2cB6xGY60VxvI9urUVrbRxsVojo/eZ3ufXPn6P3Jj/2H+SySBukvurn+THD07dRoofzOz9Mgbxi/J4Z+4Z/ad1AFoXolOUfPkf8tvY/RgpwtBB9jpIu2W9jy/RGSDW+PArPvzf/C5U7b7flaQ1Ge+TeOE7ZMHZUiekc0vskz86F0jhlt7ju++I1EqNW9Zah/+S+JC5G/NP+laDj3UVPdntLPHxfp6c7Wb6GqwlMi3A0YH5KFZIXAttUPfhD6GVdIqDOXp10ZopP5HGpmP8o5fJ2pqqWp4roly5upxn5Fy2o8w2I+2uWO1lLbShXv9thf27apF/bO4iX+GpI9dDn090riO9LGi70TqCc+R0ZnNkTgT7joue0hI1y9cP1WKdVYgeQ7kzuSZ8rLTD8b7OrVVOmLVSO9R3rir9lbSs9d9kPp8Z/5T/TJWbWkOLcd8i8VidrGOuxPdI6I+Dn/wsvwu/lDjFnEx8owEAAAAgOToaAAAAAJKjowEAAAAgubJqNH7YZNbSOyDt6/LgVIllwOI+eo9pM5urN3v/gQ+XysA+reHIFwHIgLbJfuDza6VuwSw/1m8gxucWG9eq0ziE6BhTHbv5hMSau9/+3MdfObTLL/il3Iv++Lfm9uET837l4qXyi/XuUyXv8a15uFXiowPPmXidj1vlca1/OUvi0ZfIPb9ljPijsv37A/swGMaBa02GTllyvhZy3dAmC+7x4T5+HO7JgQH7Wg9RjTHLOmZVx1F3yvtvZjZVlun7r/Oq6B3333mEjAi/cS8f3+7nvTktN7lHfgzxmvwqA07/0qU1AWaWb2i5I1bOAtf4bF4ia29pLoJ6F/o9cmPjtWDskE4fj/Jhrc5fELLGCuPl2+Wxr0pc7Ppplr9Oa371OnGUbiC3QObSWeYHyGvtkFm+TqRe5arWunSBtrSJLmo2mUunBmmb0ppirR99o3wGMzMbJ8ukrMNOOlgW3HKLLNAiD6mclTap1W1mlZlHiG80AAAAACRHRwMAAABAcnQ0AAAAACRXVo2GLbHCINpx8thCiXVAsK5vZvYuieWevnP/LLEO0NbhaDbFhy/4Go1aGYurdSF6y3wdXh0aP6pjN3Ud/V113J2OKz/cl1vY2579nl+w/cfyOzHTP2msvH/Be+JXmI6T1Hk2zMwekljH2sqUBDb69bqF6T6UsbZXy9paL1OvWiXWIcgX6vjRFVJHYHKv9Ol+5O6p0mD0NvRmlZmbpb/02PqPwDp6vBXTKvHf5Ng64de+JsMOPsKFMw7O3yB9D6lR03NINc6POjJbbxNvZman6gK5MOhRL/NmHHqcj78tzx6ouZSqITfGX+siD3nSx0P9qPDW4AwTtanvnAb6nlbiPW6V+Bhd4SL9O66c4E704U2B16ileUrKoZ9xdOYb21MXjKjYvlSLfhbRqZJC9TetEs/XFQ7XBZMlvsuHN/srz7dW+4fvCexDJdoc32gAAAAASI6OBgAAAIDk6GgAAAAASK68Go2XrDCAS4YbrpX7/y7R5/4lv7kZt/v40L1lBb0f/dF6p+lTJJYZC/Zf5sKpq/L7IHenz4237jvOLjOzDflNlE1vC/9+ic+R7t/awMQan5NYh94Wq9nQWGbNyCdi+878TsiL5O6VXaP0dy86TvwCXSCjL8/wob4XOlazHoTun/9miS95nSy4ZbwskOKWD/3Ehe1yPGpNRucW9666NDetEodqHXSejGJtQo/f3DREcu60g2Wv9s9vc2ep0dC/MlWjRkNnVnlfaKVJMrvGY7N9rIOKx/+jC/c72N/RvhZrVVIIzb+k48JzBUTn6cQa/pjdWWo0tJ6tHs9tsbTuQA+xQ+boM+TzyapLXXiZnBRy75XVb1vUc2SuzHFfPfK1RsNXUurcRYOVzpvxaf2weLauIXXJtsCHMpGYHv5/K3nP+odvNAAAAAAkR0cDAAAAQHJ0NAAAAAAkV16Nxmes0DX5sn9o/Lk+/rQfjh2eTEAHfOotgUfrEyZKrDMi/NSHn/XheYEbF39UnqLj62/p8/+NZvb9/CZKMsQK9/jWX+uTurLkavx2+e1d+Q4fL5cdv1PW75RY72t90vay4HU6hjI/I8WGW32s9S6940uz3DNryy4Sf1RXeOduPl7t5w9ZKrf1f1CeXo/jbEPT3pytC1boAhmJ+1l/EviaTGBwjTy7XuYz0NxoXYG0FjMz05HwGmtNxiiJ5+oG36oL5AAOJFPH04fG9FeajnPXM/q2wSKNPXz4uXt9fLesfqdcFyR5e0qNxi0+rMvj1Sy8349KfL+cxifqNVNyrdMdNEscmuNpsNLf/e26wjd0gcwbJCUbN8raWsdVL/SYNsufI498ja4xT2KZz2W5z4Z+0qvXY7QvnT/NLDBvxkpd8AWJf+TDs/y58RxJq85tNlB55BsNAAAAAMnR0QAAAACQHB0NAAAAAMnR0QAAAACQXFnF4AsfMWva/P8LpBi55ZOystas7BPYYKgapi+tVFkx08ft8rjOanWUxCfkX2KsVP6eIAXO7+gzWVuXxReDb7JCMbgW0GmZ9Qx98rbL8xtc4UsYZ2fn+1grzXQ2IK0GP1artaQsadWi3C7ofIpaDF6r9B4Emu8d5cYGZrv6cJ5PphY112OBpBb0aTGymdk+O8iCTolP99XhV/27f/irsnro/hC1SHOjcyidKvF238xv42htFD+QWGfM1HmZ5MYWNu0sWfAdF234bn4ftKCyGvQvW7mJIYPXBDn+9r83tFIfMuXmLD9xqxaq6vur8//VM52QSwvfJ67/nl8w8mMunCBv2HbVuINAjdCm+Q5dYezBPl5/hQt//Dv/sJ8KsX4LnEN/rT5AF+j5K5e9H/rwiz68R9aux2NUz3VTA+u8U2fF3e+DskBu6bHySy5cLpML62e0zi3uXWXxjQYAAACA5OhoAAAAAEiOjgYAAACA5Mqq0fixFXomWg7x5ot9PFXi/QPb0ynh/iqx1i7cIbGON9XxqHvLOOWDAuOWZSoo07nxftPn/xvyT4+iw7F17PqMabLggdn5jQy9yMcNUscxRwfUPyXxGoll1rnHFvlYxw5a/dYmNEmcG096nMRP+gn6VvgwN/laPY611X3+c2CdC+UAmyWJu0HW1zKELU3oWOuK5WaJxAvyc1uaXSQ1UAtnyQoTJNYRvcMkloma5vrsfiawC2skrkb+dWy1Xke69GRoZi2XyKxVH9b6FM3NYT7s9DUaOnHhYLZR4t9KvEDGwttFkmspj3ntah9rfUu9HNMxtLavRVd4RmaCfK8Ptb6zs997VBtCE/blSq1erwvu8uHaj7hwuVxjB0M9i57Rc587zAIz9ul0wh/34Qd86KuC8hN2VgvfaAAAAABIjo4GAAAAgOToaAAAAABIrqwajeetMBeEjkvXsbZXS9wc2J6OWdOxszrmX8f3aqzj9u6X+D8D+6CzR+h+9t2nVLcQ199Ta03myjjYM3VwqJlNmXO6X6A38589UhZItu9Z6+MrfXj/5T4OjfkeDLUJZoHakm9LfJMPvyMPdybdm9oQmhNFx39qbcLTEncm25vaorVkl0n8kswfYmZ26i+f9wu+dr2PZ8jsHF2SzaWywTN8eJbUz8jWzaw2a6i03uWMwDrfeIvkbqWfM8iGHu7jZxb5WErc9Hxbj/fkL5X+bndKfJu01QOH+9HwG+Ra9CqeRiN3ftND8thjfHyN1BncLesPlnYX+j1kOjLb8C4fb3uur8mw83yo1xo959Yj/dz3h9BKWjNlMqmXHK+ny4VapmqpmTbGNxoAAAAAkqOjAQAAACC5koZOZVn28r99l+k6EutXrKGvXHWoTbHnFHvNcvcptGxr+9T7/958lCKUu2L7oF93PRt4Tpeu9JyuUCSbutGNW3849BVcsfdHl5eTt77rl/es4nS/9SvNrhdlgTQKzUWxdtcfMblLkbfQc8s5Vvr7+ilUKnf6mOYhdBvsLl0pd7zKVruKbFRW1yYbOteV834MVLvT/dTbsZqZdf1dF0g89O9bf1xepNLHb7WO2VIUbYbSkLTZ6VvxasqdtlUZ0Jdrp/p4Jc+P1bzGhp5b7JB9SS+6spHBeI3VdYPnumIXE3m82Hm/0sdEybnLStDR0ZFt3iY/ZllHR0cpaSN3/cgbuYvPHXkjd+Su+j/kjtzVct7IXXzuyFt5uWvIsuLduJ6eHlu3bp01NzdbQ0NDsdUHrSzLrLu729ra2qyxsbRRZ+QuLm9m5M6MNtcf5C4euYtH7uKRuzhcY+PR5uKVmruSOhoAAAAAUA6KwQEAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJ0NAAAAAAkR0cDAAAAQHJDS1mpp6fH1q1bZ83NzdbQ0FDpfapZWZZZd3e3tbW1WWNjaX00cheXNzNyZ0ab6w9yF4/cxSN38chdHK6x8Whz8UrOXVaCjo6OzMz42fzT0dFRStrIXT/yRu7ic0feyB25q/4PuSN3tZw3chefO/JWXu5K+kajubnZzMw6OjqspaWllKcMSl1dXTZu3LhX8lEKcheXNzNyZ0ab6w9yF4/cxSN38chdHK6x8Whz8UrNXUkdjd6vhlpaWl7VSe1Vzldl5K6g3K8YyV0BbS4euYtH7uKRu3jkLg7X2Hi0uXjFckcxOAAAAIDk6GgAAAAASK6koVP9NeFTP80tW3PBnIF4aWzGe1C7eG8KyEUBuai+WnsPam1/Xo1eje+B/s6D/fdFQYr2zjcaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAgOToaAAAAAJKjowEAAAAguaGlrJRlmZmZdXV1Rb1Iz4vP55bFbquaeve5Nx+l6G/uUqnmexCTt77rVzt3lba196ae21yMlO203nO3pVzs3X5TbvkfzpmV9LXrPXepxLTHSuZusFxLt6Qe2l013wM99nuP+0pfY/V3ps0NvnPdliT5fJKVoKOjIzMzfjb/dHR0lJI2ctePvJG7+NyRN3JH7qr/Q+7IXS3njdzF5468lZe7hiwr3o3r6emxdevWWXNzszU0NJjZyz2ZcePGWUdHh7W0tBTbRFLVeu0sy6y7u9va2tqssbG0UWfkLi5vZuTOLF2bM6te7ur9eDUjd6XgeH0ZuYtH7uIMhmtsvbc5M3K3JSUNnWpsbLRddtkl+FhLS8uAH8jVfO0ddtihrPXJ3cvKzZsZueuVss2ZVS939X68mpG7reF4LSB38chdnMFyja33NmdG7hTF4AAAAACSo6MBAAAAILnojsawYcOsvb3dhg0blnJ/av61UyB38chdvGrtf73nzYzcxeJ4jUfu4pG7eJzr4pG7sJKKwQEAAACgHAydAgAAAJAcHQ0AAAAAydHRAAAAAJAcHQ0AAAAAyUV3NC6//HKbMGGCDR8+3KZPn26rVq1KuV9BixYtsoaGBvczceLEir9uagOdu8GSNzNyF4vjNR65i0fu4nGui0fu4nC8xiN3WxbV0Vi6dKktXLjQ2tvb7e6777bJkyfbrFmzbP369an3L2fSpEn22GOPvfJz6623Vvw1U6pW7uo9b2bkLhbHazxyF4/cxeNcF4/cxeF4jUfuisgiTJs2LTvllFNeiTdt2pS1tbVl559/fszmStbe3p5Nnjy5oq9RadXI3WDIW5aRu1gcr/HIXTxyF49zXTxyF4fjNR6527qyv9HYuHGj3XXXXTZz5sxXljU2NtrMmTPt9ttvT9oJCnnwwQetra3NdtttNzvuuONs7dq1FX/NVKqZu3rOmxm5i8XxGo/cxSN38TjXxSN3cThe45G74sruaDz55JO2adMmGzVqlFs+atQoe/zxx5PtWMj06dNt8eLFtnz5crviiits9erVdtBBB1l3d3dFXzeVauWu3vNmRu5icbzGI3fxyF08znXxyF0cjtd45K64odXegXIcccQRr/x/3333tenTp9uuu+5q1113nc2bN6+Ke1bbyFs8cheP3MUjd/HIXRzyFo/cxSN38eold2V/ozFixAgbMmSIPfHEE275E088YaNHj062Y6VobW21vfbayx566KEBfd1YtZK7esubGbmLVSt5MyN3/UHu4pG7OPWWNzNyF6tW8mZG7vqjVnNXdkejqanJpkyZYitXrnxlWU9Pj61cudLe9KY3Jd25Yp599ll7+OGHbcyYMQP6urFqJXf1ljczcherVvJmRu76g9zFI3dx6i1vZuQuVq3kzYzc9UfN5i6mgvzaa6/Nhg0bli1evDi77777svnz52etra3Z448/nrpY3TnttNOym2++OVu9enV22223ZTNnzsxGjBiRrV+/vqKvm1I1cjcY8pZl5C4Wx2s8cheP3MXjXBeP3MXheI1H7rYuqqORZVl26aWXZuPHj8+ampqyadOmZXfccUfK/QqaO3duNmbMmKypqSkbO3ZsNnfu3Oyhhx6q+OumNtC5Gyx5yzJyF4vjNR65i0fu4nGui0fu4nC8xiN3W9aQZVlW7W9VAAAAAAwuUTODAwAAAMDW0NEAAAAAkBwdDQAAAADJ0dEAAAAAkBwdDQAAAADJ0dEAAAAAkBwdDQAAAADJ0dEAAAAAkBwdDQAAAADJ0dEAAAAAkBwdDQAAAADJ0dEAAAAAkNz/A+bFZbJhzAFWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "# Initialize counter and error\n",
        "ctr, err = 0, 0\n",
        "for i in range(len(X_test_mx)):\n",
        "    ctr += 1\n",
        "    x = X_test_mx[i].reshape((256,1))\n",
        "    y = int(y_test_mx[i].asscalar())\n",
        "    post = bayespost(x)\n",
        "    if (post[y] < post.max()):\n",
        "        err += 1\n",
        "print('Naive Bayes has an error rate of', err/ctr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB1WOd2SHIlm",
        "outputId": "d58bd49c-da3d-456c-f55c-af8eb19d1df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes has an error rate of 0.15197132616487455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICAB_43QZsFP"
      },
      "source": [
        "## &#52;. Multiple Regression\n",
        "\n",
        "Consider Communities and Crime dataset within the United States. The data combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR.\n",
        "It contains 1 goal attribute and 128 attributes:\n",
        "\n",
        "1.   @attribute state numeric  \n",
        "2.   @attribute county numeric  \n",
        "3.   @attribute community numeric  \n",
        "4.   @attribute communityname string  \n",
        "5.   @attribute fold numeric  \n",
        "6.   @attribute population numeric  \n",
        "7.   @attribute householdsize numeric  \n",
        "8.   @attribute racepctblack numeric  \n",
        "9.   @attribute racePctWhite numeric  \n",
        "10.  @attribute racePctAsian numeric  \n",
        "11.  @attribute racePctHisp numeric  \n",
        "12.  @attribute agePct12t21 numeric  \n",
        "13.  @attribute agePct12t29 numeric  \n",
        "14.  @attribute agePct16t24 numeric  \n",
        "15.  @attribute agePct65up numeric  \n",
        "16.  @attribute numbUrban numeric  \n",
        "17.  @attribute pctUrban numeric  \n",
        "18.  @attribute medIncome numeric  \n",
        "19.  @attribute pctWWage numeric  \n",
        "20.  @attribute pctWFarmSelf numeric  \n",
        "21.  @attribute pctWInvInc numeric  \n",
        "22.  @attribute pctWSocSec numeric  \n",
        "23.  @attribute pctWPubAsst numeric  \n",
        "24.  @attribute pctWRetire numeric  \n",
        "25.  @attribute medFamInc numeric  \n",
        "26.  @attribute perCapInc numeric  \n",
        "27.  @attribute whitePerCap numeric  \n",
        "28.  @attribute blackPerCap numeric  \n",
        "29.  @attribute indianPerCap numeric  \n",
        "30.  @attribute AsianPerCap numeric  \n",
        "31.  @attribute OtherPerCap numeric  \n",
        "32.  @attribute HispPerCap numeric  \n",
        "33.  @attribute NumUnderPov numeric  \n",
        "34.  @attribute PctPopUnderPov numeric  \n",
        "35.  @attribute PctLess9thGrade numeric  \n",
        "36.  @attribute PctNotHSGrad numeric  \n",
        "37.  @attribute PctBSorMore numeric  \n",
        "38.  @attribute PctUnemployed numeric  \n",
        "39.  @attribute PctEmploy numeric  \n",
        "40.  @attribute PctEmplManu numeric  \n",
        "41.  @attribute PctEmplProfServ numeric  \n",
        "42.  @attribute PctOccupManu numeric  \n",
        "43.  @attribute PctOccupMgmtProf numeric  \n",
        "44.  @attribute MalePctDivorce numeric  \n",
        "45.  @attribute MalePctNevMarr numeric  \n",
        "46.  @attribute FemalePctDiv numeric  \n",
        "47.  @attribute TotalPctDiv numeric  \n",
        "48.  @attribute PersPerFam numeric  \n",
        "49.  @attribute PctFam2Par numeric  \n",
        "50.  @attribute PctKids2Par numeric  \n",
        "51.  @attribute PctYoungKids2Par numeric  \n",
        "52.  @attribute PctTeen2Par numeric  \n",
        "53.  @attribute PctWorkMomYoungKids numeric  \n",
        "54.  @attribute PctWorkMom numeric  \n",
        "55.  @attribute NumIlleg numeric   \n",
        "56.  @attribute PctIlleg numeric  \n",
        "57.  @attribute NumImmig numeric  \n",
        "58.  @attribute PctImmigRecent numeric  \n",
        "59.  @attribute PctImmigRec5 numeric  \n",
        "60.  @attribute PctImmigRec8 numeric  \n",
        "61.  @attribute PctImmigRec10 numeric  \n",
        "62.  @attribute PctRecentImmig numeric  \n",
        "63.  @attribute PctRecImmig5 numeric  \n",
        "64.  @attribute PctRecImmig8 numeric  \n",
        "65.  @attribute PctRecImmig10 numeric  \n",
        "66.  @attribute PctSpeakEnglOnly numeric  \n",
        "67.  @attribute PctNotSpeakEnglWell numeric  \n",
        "68.  @attribute PctLargHouseFam numeric  \n",
        "69.  @attribute PctLargHouseOccup numeric  \n",
        "70.  @attribute PersPerOccupHous numeric  \n",
        "71.  @attribute PersPerOwnOccHous numeric  \n",
        "72.  @attribute PersPerRentOccHous numeric  \n",
        "73.  @attribute PctPersOwnOccup numeric  \n",
        "74.  @attribute PctPersDenseHous numeric  \n",
        "75.  @attribute PctHousLess3BR numeric  \n",
        "76.  @attribute MedNumBR numeric  \n",
        "77.  @attribute HousVacant numeric  \n",
        "78.  @attribute PctHousOccup numeric  \n",
        "79.  @attribute PctHousOwnOcc numeric  \n",
        "80.  @attribute PctVacantBoarded numeric  \n",
        "81.  @attribute PctVacMore6Mos numeric  \n",
        "82.  @attribute MedYrHousBuilt numeric  \n",
        "83.  @attribute PctHousNoPhone numeric  \n",
        "84.  @attribute PctWOFullPlumb numeric  \n",
        "85.  @attribute OwnOccLowQuart numeric  \n",
        "86.  @attribute OwnOccMedVal numeric  \n",
        "87.  @attribute OwnOccHiQuart numeric  \n",
        "88.  @attribute RentLowQ numeric  \n",
        "89.  @attribute RentMedian numeric  \n",
        "90.  @attribute RentHighQ numeric  \n",
        "91.  @attribute MedRent numeric  \n",
        "92.  @attribute MedRentPctHousInc numeric  \n",
        "93.  @attribute MedOwnCostPctInc numeric  \n",
        "94.  @attribute MedOwnCostPctIncNoMtg numeric  \n",
        "95.  @attribute NumInShelters numeric  \n",
        "96.  @attribute NumStreet numeric  \n",
        "97.  @attribute PctForeignBorn numeric  \n",
        "98.  @attribute PctBornSameState numeric  \n",
        "99.  @attribute PctSameHouse85 numeric  \n",
        "100. @attribute PctSameCity85 numeric  \n",
        "101. @attribute PctSameState85 numeric  \n",
        "102. @attribute LemasSwornFT numeric  \n",
        "103. @attribute LemasSwFTPerPop numeric  \n",
        "104. @attribute LemasSwFTFieldOps numeric  \n",
        "105. @attribute LemasSwFTFieldPerPop numeric  \n",
        "106. @attribute LemasTotalReq numeric  \n",
        "107. @attribute LemasTotReqPerPop numeric  \n",
        "108. @attribute PolicReqPerOffic numeric  \n",
        "109. @attribute PolicPerPop numeric  \n",
        "110. @attribute RacialMatchCommPol numeric  \n",
        "111. @attribute PctPolicWhite numeric  \n",
        "112. @attribute PctPolicBlack numeric  \n",
        "113. @attribute PctPolicHisp numeric  \n",
        "114. @attribute PctPolicAsian numeric  \n",
        "115. @attribute PctPolicMinor numeric  \n",
        "116. @attribute OfficAssgnDrugUnits numeric  \n",
        "117. @attribute NumKindsDrugsSeiz numeric  \n",
        "118. @attribute PolicAveOTWorked numeric  \n",
        "119. @attribute LandArea numeric  \n",
        "120. @attribute PopDens numeric  \n",
        "121. @attribute PctUsePubTrans numeric  \n",
        "122. @attribute PolicCars numeric  \n",
        "123. @attribute PolicOperBudg numeric  \n",
        "124. @attribute LemasPctPolicOnPatr numeric  \n",
        "125. @attribute LemasGangUnitDeploy numeric  \n",
        "126. @attribute LemasPctOfficDrugUn numeric  \n",
        "127. @attribute PolicBudgPerPop numeric  \n",
        "128. @attribute ViolentCrimesPerPop numeric  \n",
        "\n",
        "\n",
        "There are missing values.\n",
        "\n",
        "You must implement the multiple regression using SGD from our class.\n",
        "- The total 10 points will give to a student who can find the parameters of this regression and achieve 0.01 for the average square loss.\n",
        "- The total 8 points will give to a student who can find the parameters of this regression and achieve 0.05 for the average square loss.\n",
        "- The total 6 points will give to a student who can find the parameters of this regression and achieve 0.1 for the average square loss.\n",
        "- The total 5 points will give to a student who can make this code work with this dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LviDXvfPZsFQ",
        "outputId": "15b18e34-26ef-498a-e665-1e50cf653d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "# Download dataset and unzip\n",
        "!wget https://archive.ics.uci.edu/static/public/183/communities+and+crime.zip\n",
        "!unzip communities+and+crime.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-01 05:51:57--  https://archive.ics.uci.edu/static/public/183/communities+and+crime.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘communities+and+crime.zip’\n",
            "\n",
            "communities+and+cri     [  <=>               ] 264.69K  1004KB/s    in 0.3s    \n",
            "\n",
            "2024-03-01 05:51:57 (1004 KB/s) - ‘communities+and+crime.zip’ saved [271040]\n",
            "\n",
            "Archive:  communities+and+crime.zip\n",
            "  inflating: communities.data        \n",
            "  inflating: communities.names       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "# Read data and set column names.\n",
        "filename = \"communities.data\"\n",
        "df = pd.read_csv(filename, header=None)\n",
        "df.columns = [\"state\", \"county\", \"community\", \"communityname\", \"fold\", \"population\",\n",
        "\"householdsize\", \"racepctblack\", \"racePctWhite\", \"racePctAsian\", \"racePctHisp\",\n",
        "\"agePct12t21\", \"agePct12t29\", \"agePct16t24\", \"agePct65up\", \"numbUrban\", \"pctUrban\",\n",
        "\"medIncome\", \"pctWWage\", \"pctWFarmSelf\", \"pctWInvInc\", \"pctWSocSec\", \"pctWPubAsst\",\n",
        "\"pctWRetire\", \"medFamInc\", \"perCapInc\", \"whitePerCap\", \"blackPerCap\", \"indianPerCap\",\n",
        "\"AsianPerCap\", \"OtherPerCap\", \"HispPerCap\", \"NumUnderPov\", \"PctPopUnderPov\",\n",
        "\"PctLess9thGrade\", \"PctNotHSGrad\", \"PctBSorMore\", \"PctUnemployed\", \"PctEmploy\",\n",
        "\"PctEmplManu\", \"PctEmplProfServ\", \"PctOccupManu\", \"PctOccupMgmtProf\", \"MalePctDivorce\",\n",
        "\"MalePctNevMarr\", \"FemalePctDiv\", \"TotalPctDiv\", \"PersPerFam\", \"PctFam2Par\", \"PctKids2Par\",\n",
        "\"PctYoungKids2Par\", \"PctTeen2Par\", \"PctWorkMomYoungKids\", \"PctWorkMom\", \"NumIlleg\",\n",
        "\"PctIlleg\", \"NumImmig\", \"PctImmigRecent\", \"PctImmigRec5\", \"PctImmigRec8\", \"PctImmigRec10\",\n",
        "\"PctRecentImmig\", \"PctRecImmig5\", \"PctRecImmig8\", \"PctRecImmig10\", \"PctSpeakEnglOnly\",\n",
        "\"PctNotSpeakEnglWell\", \"PctLargHouseFam\", \"PctLargHouseOccup\", \"PersPerOccupHous\",\n",
        "\"PersPerOwnOccHous\", \"PersPerRentOccHous\", \"PctPersOwnOccup\", \"PctPersDenseHous\",\n",
        "\"PctHousLess3BR\", \"MedNumBR\", \"HousVacant\", \"PctHousOccup\", \"PctHousOwnOcc\",\n",
        "\"PctVacantBoarded\", \"PctVacMore6Mos\", \"MedYrHousBuilt\", \"PctHousNoPhone\", \"PctWOFullPlumb\",\n",
        "\"OwnOccLowQuart\", \"OwnOccMedVal\", \"OwnOccHiQuart\", \"RentLowQ\", \"RentMedian\", \"RentHighQ\",\n",
        "\"MedRent\", \"MedRentPctHousInc\", \"MedOwnCostPctInc\", \"MedOwnCostPctIncNoMtg\", \"NumInShelters\",\n",
        "\"NumStreet\", \"PctForeignBorn\", \"PctBornSameState\", \"PctSameHouse85\", \"PctSameCity85\",\n",
        "\"PctSameState85\", \"LemasSwornFT\", \"LemasSwFTPerPop\", \"LemasSwFTFieldOps\",\n",
        "\"LemasSwFTFieldPerPop\", \"LemasTotalReq\", \"LemasTotReqPerPop\", \"PolicReqPerOffic\",\n",
        "\"PolicPerPop\", \"RacialMatchCommPol\", \"PctPolicWhite\", \"PctPolicBlack\", \"PctPolicHisp\",\n",
        "\"PctPolicAsian\", \"PctPolicMinor\", \"OfficAssgnDrugUnits\", \"NumKindsDrugsSeiz\",\n",
        "\"PolicAveOTWorked\", \"LandArea\", \"PopDens\", \"PctUsePubTrans\", \"PolicCars\", \"PolicOperBudg\",\n",
        "\"LemasPctPolicOnPatr\", \"LemasGangUnitDeploy\", \"LemasPctOfficDrugUn\", \"PolicBudgPerPop\",\n",
        "\"ViolentCrimesPerPop\"]"
      ],
      "metadata": {
        "id": "e6R-1Hdi27XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "# Need to drop column with some missing values\n",
        "ColumnDrops = ['county', 'community', 'communityname', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy',\n",
        "               'PolicBudgPerPop', 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked',\n",
        "               'PolicPerPop','RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'OtherPerCap',\n",
        "               'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic',\n",
        "               'LemasSwornFT', 'LemasSwFTPerPop']\n",
        "for col in ColumnDrops:\n",
        "  df = df.drop(col, axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "MpMJAyuL3I6w",
        "outputId": "e555c4da-81fd-4c16-9a68-73263e0b722c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   state  fold  population  householdsize  racepctblack  racePctWhite  \\\n",
              "0      8     1        0.19           0.33          0.02          0.90   \n",
              "1     53     1        0.00           0.16          0.12          0.74   \n",
              "2     24     1        0.00           0.42          0.49          0.56   \n",
              "3     34     1        0.04           0.77          1.00          0.08   \n",
              "4     42     1        0.01           0.55          0.02          0.95   \n",
              "\n",
              "   racePctAsian  racePctHisp  agePct12t21  agePct12t29  ...  PctForeignBorn  \\\n",
              "0          0.12         0.17         0.34         0.47  ...            0.12   \n",
              "1          0.45         0.07         0.26         0.59  ...            0.21   \n",
              "2          0.17         0.04         0.39         0.47  ...            0.14   \n",
              "3          0.12         0.10         0.51         0.50  ...            0.19   \n",
              "4          0.09         0.05         0.38         0.38  ...            0.11   \n",
              "\n",
              "   PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  LandArea  \\\n",
              "0              0.42            0.50           0.51            0.64      0.12   \n",
              "1              0.50            0.34           0.60            0.52      0.02   \n",
              "2              0.49            0.54           0.67            0.56      0.01   \n",
              "3              0.30            0.73           0.64            0.65      0.02   \n",
              "4              0.72            0.64           0.61            0.53      0.04   \n",
              "\n",
              "   PopDens  PctUsePubTrans  LemasPctOfficDrugUn  ViolentCrimesPerPop  \n",
              "0     0.26            0.20                 0.32                 0.20  \n",
              "1     0.12            0.45                 0.00                 0.67  \n",
              "2     0.21            0.02                 0.00                 0.43  \n",
              "3     0.39            0.28                 0.00                 0.12  \n",
              "4     0.09            0.02                 0.00                 0.03  \n",
              "\n",
              "[5 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2f1627b-1239-4816-9676-1129c4e4c52a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>fold</th>\n",
              "      <th>population</th>\n",
              "      <th>householdsize</th>\n",
              "      <th>racepctblack</th>\n",
              "      <th>racePctWhite</th>\n",
              "      <th>racePctAsian</th>\n",
              "      <th>racePctHisp</th>\n",
              "      <th>agePct12t21</th>\n",
              "      <th>agePct12t29</th>\n",
              "      <th>...</th>\n",
              "      <th>PctForeignBorn</th>\n",
              "      <th>PctBornSameState</th>\n",
              "      <th>PctSameHouse85</th>\n",
              "      <th>PctSameCity85</th>\n",
              "      <th>PctSameState85</th>\n",
              "      <th>LandArea</th>\n",
              "      <th>PopDens</th>\n",
              "      <th>PctUsePubTrans</th>\n",
              "      <th>LemasPctOfficDrugUn</th>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.47</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.59</td>\n",
              "      <td>...</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>...</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 102 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2f1627b-1239-4816-9676-1129c4e4c52a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2f1627b-1239-4816-9676-1129c4e4c52a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2f1627b-1239-4816-9676-1129c4e4c52a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2b57bc32-01b0-4471-8013-eb5ef9400e73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b57bc32-01b0-4471-8013-eb5ef9400e73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2b57bc32-01b0-4471-8013-eb5ef9400e73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjGHlOHCghOr",
        "outputId": "6d635d95-4962-4170-f23a-a049165cc147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "\n",
        "# We will need to process this text dataset using pandas\n",
        "# Keeping only continuous variables and scale each column to be in [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(df)\n",
        "df.loc[:,:] = scaled_values\n",
        "\n",
        "# Get attributes and target\n",
        "num_inputs, num_outputs = xxx, xx\n",
        "X = mx.nd.array(df.drop(['ViolentCrimesPerPop'], axis=1))\n",
        "y = mx.nd.array(df['ViolentCrimesPerPop'])\n",
        "num_examples = len(y)\n",
        "print(num_examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "\n",
        "## Update this code to build the multiple regression the last epoch must have average square loss less than 0.001\n",
        "# Build multiple regression from ground-up\n",
        "mx.random.seed(1)\n",
        "batch_size = xx\n",
        "train_data = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(X, y), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "w = nd.random_normal(loc=0, scale=1, shape=(num_inputs, num_outputs))\n",
        "b = nd.random_normal(shape=num_outputs)\n",
        "params = [w, b]\n",
        "for param in params:\n",
        "    param.attach_grad()\n",
        "def net(X):\n",
        "    return mx.nd.dot(X, w) + b\n",
        "def square_loss(yhat, y):\n",
        "    return nd.mean((yhat - y)**2)\n",
        "def SGD(params, lr):\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad\n",
        "num_batches = num_examples/batch_size"
      ],
      "metadata": {
        "id": "U8AHjW0OLaob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "\n",
        "epochs, learning_rate = xxx, xx\n",
        "for e in range(epochs):\n",
        "    cumulative_loss = 0.0\n",
        "    # inner loop\n",
        "    for data, label in train_data:\n",
        "        label = label.reshape((-1, 1))\n",
        "        with autograd.record():\n",
        "            output = net(data)\n",
        "            loss = square_loss(output, label)\n",
        "        loss.backward()\n",
        "        SGD(params, learning_rate)\n",
        "        cumulative_loss += loss.asscalar()\n",
        "    if e%200==0:\n",
        "      print(\"The cumulative loss of epoch %3d is %10.8f\"%(e, cumulative_loss / num_batches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhXZ8F8RCDYr",
        "outputId": "411320cb-b073-4e68-95e9-9c59380b3ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cumulative loss of epoch   0 is 1.60320066\n",
            "The cumulative loss of epoch 200 is 0.11181477\n",
            "The cumulative loss of epoch 400 is 0.10555065\n",
            "The cumulative loss of epoch 600 is 0.10020455\n",
            "The cumulative loss of epoch 800 is 0.09878540\n",
            "The cumulative loss of epoch 1000 is 0.09908978\n",
            "The cumulative loss of epoch 1200 is 0.09820114\n",
            "The cumulative loss of epoch 1400 is 0.09923699\n",
            "The cumulative loss of epoch 1600 is 0.09821831\n",
            "The cumulative loss of epoch 1800 is 0.09923270\n",
            "The cumulative loss of epoch 2000 is 0.10225643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMrr9BylCOc7",
        "outputId": "de9f4324-9122-4408-ed23-f02aa1a9d152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cumulative loss of epoch   0 is 0.09066828\n",
            "The cumulative loss of epoch 100 is 0.08711926\n",
            "The cumulative loss of epoch 200 is 0.08729746\n",
            "The cumulative loss of epoch 300 is 0.08725504\n",
            "The cumulative loss of epoch 400 is 0.08719487\n",
            "The cumulative loss of epoch 500 is 0.08690993\n",
            "The cumulative loss of epoch 600 is 0.08727646\n",
            "The cumulative loss of epoch 700 is 0.08687309\n",
            "The cumulative loss of epoch 800 is 0.08699187\n",
            "The cumulative loss of epoch 900 is 0.08709959\n",
            "The cumulative loss of epoch 1000 is 0.08713880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwFIBUl1JKyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## &#53;. Softmax regression (10 points)\n",
        "\n",
        "You will use the multiclass logistic (softmax) regression to solve usps dataset.\n",
        "\n",
        "You can use mxnet.gluon from our class.\n",
        "\n",
        "- The total 10 points will give to a student who can find the parameters of this perceptron achieving more than 95% testing accuracy.\n",
        "- The total 8 points will give to a student who can find the parameters of this perceptron achieving more than 90% testing accuracy.\n",
        "- The total 6 points will give to a student who can find the parameters of this perceptron achieving more than 80% testing accuracy.\n",
        "- The total 5 points will give to a student who can make this code work with this dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "3lxwZ8zh_bth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update preprocessing here\n",
        "# Download and preprocess the USPS dataset\n",
        "usps = fetch_openml('usps', version=2, data_home='.')\n",
        "usps.data = usps.data\n",
        "usps.target = usps.target\n",
        "\n",
        "# Split data into training and testing sets (optional)\n",
        "X_train, X_test, y_train, y_test = train_test_split(usps.data, usps.target, test_size=0.3, random_state=1, stratify=usps.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wfCwoX5CcqK",
        "outputId": "adf958a3-1060-47c1-ec93-4936ceb4a550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################################\n",
        "# Replace xx with appropriate values #\n",
        "######################################\n",
        "\n",
        "batch_size = xx\n",
        "train_iter = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(X_train.to_numpy(), y_train.to_numpy()), batch_size=batch_size, shuffle=True)\n",
        "test_iter = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(X_test.to_numpy(), y_test.to_numpy()), batch_size=len(y_test), shuffle=False)"
      ],
      "metadata": {
        "id": "KjsasGkZGunb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "\n",
        "# Set the number of inputs, the number of outputs\n",
        "num_inputs, num_outputs = xxx, xx\n",
        "W = nd.random.normal(scale=0.01, shape=(num_inputs, num_outputs))\n",
        "b = nd.zeros(num_outputs)\n",
        "W.attach_grad()\n",
        "b.attach_grad()"
      ],
      "metadata": {
        "id": "aUcR9OwjAvhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "def softmax(X):\n",
        "    X_exp = X.exp()\n",
        "    partition = X_exp.sum(axis=1, keepdims=True)\n",
        "    return X_exp / partition  # The broadcast mechanism is applied here.\n",
        "def net(X):\n",
        "    return softmax(nd.dot(X.reshape((-1, num_inputs)), W) + b)\n",
        "def cross_entropy(y_hat, y):\n",
        "    return - nd.pick(y_hat, y).log()"
      ],
      "metadata": {
        "id": "3jV4b3GqIjYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RuyWOvP3Rmm"
      },
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "def accuracy(y_hat, y):\n",
        "    return (y_hat.argmax(axis=1) == y.astype('float32')).mean().asscalar()\n",
        "\n",
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0.0, 0\n",
        "    for X, y in data_iter:\n",
        "        y = y.astype('float32')\n",
        "        acc_sum += (net(X).argmax(axis=1) == y).sum().asscalar()\n",
        "        n += y.size\n",
        "    return acc_sum / n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before training check the accuracy of the random network on Test\n",
        "evaluate_accuracy(test_iter, net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfE-OOmMJBa0",
        "outputId": "30201883-a38e-488b-8eec-7dec8bcb55c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07060931899641577"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "def sgd(params, lr, batch_size):\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad / batch_size"
      ],
      "metadata": {
        "id": "g9VH2TygJBek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "def train(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
        "              params=None, lr=None, trainer=None):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
        "        for X, y in train_iter:\n",
        "            with autograd.record():\n",
        "                y_hat = net(X)\n",
        "                l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            if trainer is None:\n",
        "                sgd(params, lr, batch_size)\n",
        "            else:\n",
        "                trainer.step(batch_size)\n",
        "            y = y.astype('float32')\n",
        "            train_l_sum += l.asscalar()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
        "            n += y.size\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
        "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
      ],
      "metadata": {
        "id": "iaYVT1EBJBh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "\n",
        "# First training using the high learning rate\n",
        "num_epochs, lr = xxx, xx\n",
        "train(net, train_iter, test_iter, cross_entropy, num_epochs,batch_size, [W, b], lr)"
      ],
      "metadata": {
        "id": "PkaQbnjiJBld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4561b2a-119e-40d7-e48f-57f893127215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.8323, train acc 0.819, test acc 0.897\n",
            "epoch 2, loss 0.4166, train acc 0.904, test acc 0.917\n",
            "epoch 3, loss 0.3452, train acc 0.917, test acc 0.924\n",
            "epoch 4, loss 0.3107, train acc 0.922, test acc 0.925\n",
            "epoch 5, loss 0.2896, train acc 0.927, test acc 0.930\n",
            "epoch 6, loss 0.2754, train acc 0.929, test acc 0.927\n",
            "epoch 7, loss 0.2650, train acc 0.931, test acc 0.935\n",
            "epoch 8, loss 0.2568, train acc 0.933, test acc 0.933\n",
            "epoch 9, loss 0.2496, train acc 0.934, test acc 0.935\n",
            "epoch 10, loss 0.2440, train acc 0.936, test acc 0.937\n",
            "epoch 11, loss 0.2393, train acc 0.937, test acc 0.937\n",
            "epoch 12, loss 0.2349, train acc 0.937, test acc 0.938\n",
            "epoch 13, loss 0.2312, train acc 0.938, test acc 0.939\n",
            "epoch 14, loss 0.2273, train acc 0.939, test acc 0.938\n",
            "epoch 15, loss 0.2246, train acc 0.939, test acc 0.939\n",
            "epoch 16, loss 0.2214, train acc 0.942, test acc 0.939\n",
            "epoch 17, loss 0.2192, train acc 0.942, test acc 0.942\n",
            "epoch 18, loss 0.2169, train acc 0.944, test acc 0.942\n",
            "epoch 19, loss 0.2147, train acc 0.943, test acc 0.940\n",
            "epoch 20, loss 0.2124, train acc 0.945, test acc 0.942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKzMSv49Q6SF",
        "outputId": "04bbbc2c-45bf-4549-f0f1-1f9724afd550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.2093, train acc 0.945, test acc 0.942\n",
            "epoch 2, loss 0.2091, train acc 0.945, test acc 0.942\n",
            "epoch 3, loss 0.2089, train acc 0.945, test acc 0.942\n",
            "epoch 4, loss 0.2087, train acc 0.945, test acc 0.943\n",
            "epoch 5, loss 0.2085, train acc 0.945, test acc 0.943\n",
            "epoch 6, loss 0.2084, train acc 0.945, test acc 0.943\n",
            "epoch 7, loss 0.2083, train acc 0.946, test acc 0.943\n",
            "epoch 8, loss 0.2082, train acc 0.946, test acc 0.943\n",
            "epoch 9, loss 0.2081, train acc 0.946, test acc 0.944\n",
            "epoch 10, loss 0.2080, train acc 0.946, test acc 0.944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-_i9JNjQ6WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwUh6hMfZsFX"
      },
      "source": [
        "## &#54;. Multilayer perceptron (10 points)\n",
        "\n",
        "You must use the multilayer perceptron to solve the usps dataset\n",
        "\n",
        "You can use mxnet.gluon from our class.\n",
        "- The total 10 points will give to a student who can find the parameters of this perceptron achieving more than 99% testing accuracy.\n",
        "- The total 8 points will give to a student who can find the parameters of this perceptron achieving more than 95% testing accuracy.\n",
        "- The total 6 points will give to a student who can find the parameters of this perceptron achieving more than 90% testing accuracy.\n",
        "- The total 5 points will give to a student who can make this code work with this dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS BOX\n",
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = nd.array([0]), 0\n",
        "    for X, y in data_iter:\n",
        "        # If ctx is the GPU, copy the data to the GPU.\n",
        "        y = y.astype('float32')\n",
        "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
        "        n += y.size\n",
        "    return acc_sum.asscalar() / n"
      ],
      "metadata": {
        "id": "WWc88EH6WoQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkzuGLVXZsFY",
        "outputId": "ca7a3b72-ef3d-4392-8369-9ab8c9b9c493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Perform data preprocessing for usps\n",
        "#######################################\n",
        "# Replace xxx with appropriate values #\n",
        "#######################################\n",
        "\n",
        "# Import Dataset from scikit-learn\n",
        "# Download and preprocess the USPS dataset\n",
        "usps = fetch_openml('usps', version=2, data_home='.')\n",
        "usps.data = usps.data\n",
        "usps.target = usps.target\n",
        "\n",
        "# Split data into training and testing sets (optional)\n",
        "X_train, X_test, y_train, y_test = train_test_split(usps.data, usps.target, test_size=0.3, random_state=1, stratify=usps.target)\n",
        "\n",
        "batch_size = xxx\n",
        "train_iter = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(X_train.to_numpy(), y_train.to_numpy()), batch_size=batch_size, shuffle=True)\n",
        "test_iter = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(X_test.to_numpy(), y_test.to_numpy()), batch_size=len(y_test), shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAIoSQgjXuEY"
      },
      "source": [
        "###########################################\n",
        "# Replace xx, xxx with appropriate values #\n",
        "###########################################\n",
        "# Update this MLP\n",
        "class MLP(nn.Block):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MLP, self).__init__(**kwargs)\n",
        "    self.linear1 = nn.Dense(xx, activation=\"relu\")\n",
        "    self.linear4 = nn.Dense(xx, activation=\"sigmoid\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    return self.linear4(x)\n",
        "\n",
        "model = MLP()\n",
        "model.initialize(mx.init.Xavier())\n",
        "\n",
        "learning_rate = xxx\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "trainer = mx.gluon.Trainer(model.collect_params(), \"adam\", {\"learning_rate\":learning_rate})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# Replace xxx with appropriate values #\n",
        "#######################################\n",
        "# Training\n",
        "num_epochs = xxx\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for data, label in train_iter:\n",
        "        with autograd.record():\n",
        "            output = model(data)\n",
        "            loss = loss_fn(output, label)\n",
        "        loss.backward()\n",
        "        trainer.step(data.shape[0])\n",
        "        train_loss += loss.mean().asscalar()\n",
        "        train_acc += (output.argmax(axis=1) == label.astype('float32')).mean().asscalar()\n",
        "    test_acc = evaluate_accuracy(test_iter, model)\n",
        "    if (epoch+1)%50==0:\n",
        "      print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss / len(train_iter):.4f}, Train accuracy: {train_acc / len(train_iter):.4f}, Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiTu_Ju6VXAF",
        "outputId": "2a7386e7-d116-4682-851b-719252fa7cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/1000], Loss: 1.5235, Train accuracy: 0.9368, Test accuracy: 0.9297\n",
            "Epoch [100/1000], Loss: 1.4989, Train accuracy: 0.9584, Test accuracy: 0.9434\n",
            "Epoch [150/1000], Loss: 1.4909, Train accuracy: 0.9615, Test accuracy: 0.9473\n",
            "Epoch [200/1000], Loss: 1.4860, Train accuracy: 0.9670, Test accuracy: 0.9502\n",
            "Epoch [250/1000], Loss: 1.4834, Train accuracy: 0.9690, Test accuracy: 0.9530\n",
            "Epoch [300/1000], Loss: 1.4817, Train accuracy: 0.9691, Test accuracy: 0.9523\n",
            "Epoch [350/1000], Loss: 1.4799, Train accuracy: 0.9710, Test accuracy: 0.9548\n",
            "Epoch [400/1000], Loss: 1.4793, Train accuracy: 0.9723, Test accuracy: 0.9548\n",
            "Epoch [450/1000], Loss: 1.4792, Train accuracy: 0.9723, Test accuracy: 0.9559\n",
            "Epoch [500/1000], Loss: 1.4783, Train accuracy: 0.9742, Test accuracy: 0.9545\n",
            "Epoch [550/1000], Loss: 1.4772, Train accuracy: 0.9752, Test accuracy: 0.9559\n",
            "Epoch [600/1000], Loss: 1.4774, Train accuracy: 0.9741, Test accuracy: 0.9563\n",
            "Epoch [650/1000], Loss: 1.4768, Train accuracy: 0.9752, Test accuracy: 0.9566\n",
            "Epoch [700/1000], Loss: 1.4764, Train accuracy: 0.9762, Test accuracy: 0.9566\n",
            "Epoch [750/1000], Loss: 1.4761, Train accuracy: 0.9771, Test accuracy: 0.9566\n",
            "Epoch [800/1000], Loss: 1.4781, Train accuracy: 0.9769, Test accuracy: 0.9552\n",
            "Epoch [850/1000], Loss: 1.4758, Train accuracy: 0.9774, Test accuracy: 0.9566\n",
            "Epoch [900/1000], Loss: 1.4758, Train accuracy: 0.9774, Test accuracy: 0.9570\n",
            "Epoch [950/1000], Loss: 1.4757, Train accuracy: 0.9774, Test accuracy: 0.9566\n",
            "Epoch [1000/1000], Loss: 1.4757, Train accuracy: 0.9774, Test accuracy: 0.9570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dDiHt1PQn1A4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}